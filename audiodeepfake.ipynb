{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T13:50:34.172339Z",
     "iopub.status.busy": "2025-09-30T13:50:34.171981Z",
     "iopub.status.idle": "2025-09-30T13:50:34.179898Z",
     "shell.execute_reply": "2025-09-30T13:50:34.179029Z",
     "shell.execute_reply.started": "2025-09-30T13:50:34.172313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "import torchaudio\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "import csv\n",
    "from typing import Callable, List, Optional, Tuple, Union\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "### Utils\n",
    "\n",
    "def find_wav_files(path_to_dir: Union[Path, str]) -> Optional[List[Path]]:\n",
    "    \"\"\"Find all wav files in the directory and its subtree.\n",
    "\n",
    "    Args:\n",
    "        path_to_dir: Path top directory.\n",
    "    Returns:\n",
    "        List containing Path objects or None (nothing found).\n",
    "    \"\"\"\n",
    "    paths = list(sorted(Path(path_to_dir).glob(\"**/*.wav\")))\n",
    "\n",
    "    if len(paths) == 0:\n",
    "        return None\n",
    "    return paths\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    \"\"\"Fix PRNG seed for reproducable experiments.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset-related code\n",
    "\n",
    "**AudioDataset**: This dataset-related code processes a list of .wav files and adjusts the sample rate for each voice to be the same.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**PadDataset**: This function adjusts the length of all voices to 4 seconds. If the voice is longer than 4 seconds, it is truncated to between 0 and 4 seconds. If it is shorter than 4 seconds, it is played repeatedly to adjust the length to 4 seconds. Since the data is processed in mini-batches, this process can be seen as adjusting the length of each sample within the mini-batch to be the same.\n",
    "\n",
    "**load_dataset**: This function loads the training dataset.\n",
    "\n",
    "**load_dataset_test**: This function loads the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T13:50:40.624422Z",
     "iopub.status.busy": "2025-09-30T13:50:40.623722Z",
     "iopub.status.idle": "2025-09-30T13:50:40.640954Z",
     "shell.execute_reply": "2025-09-30T13:50:40.639902Z",
     "shell.execute_reply.started": "2025-09-30T13:50:40.624390Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            directory_or_path_list: Union[Union[str, Path], List[Union[str, Path]]],\n",
    "            sample_rate: int = 16_000,\n",
    "            normalize: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.sample_rate = sample_rate\n",
    "        self.normalize = normalize\n",
    "\n",
    "        # If input is directory, find all wav files\n",
    "        if isinstance(directory_or_path_list, list):\n",
    "            paths = directory_or_path_list\n",
    "        elif isinstance(directory_or_path_list, (Path, str)):\n",
    "            directory = Path(directory_or_path_list)\n",
    "            if not directory.exists():\n",
    "                raise IOError(f\"Directory does not exist: {directory}\")\n",
    "            paths = find_wav_files(directory)\n",
    "            if paths is None:\n",
    "                raise IOError(f\"No wav files found in {directory}\")\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type: {type(directory_or_path_list)}\")\n",
    "\n",
    "        self._paths = paths\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        path = self._paths[index]\n",
    "        waveform, sample_rate = torchaudio.load(path, normalize=self.normalize)\n",
    "\n",
    "        if sample_rate != self.sample_rate:\n",
    "            transform = torchaudio.transforms.Resample(sample_rate, self.sample_rate)\n",
    "            waveform = transform(waveform)\n",
    "\n",
    "        return waveform, sample_rate\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._paths)\n",
    "\n",
    "class PadDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, dataset: torch.utils.data.Dataset, cut: int = 64600, label=None):\n",
    "        self.dataset = dataset\n",
    "        self.cut = cut  # max 4 sec (ASVSpoof default)\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        waveform, sample_rate = self.dataset[index]\n",
    "        waveform = waveform.squeeze(0)\n",
    "        waveform_len = waveform.shape[0]\n",
    "        if waveform_len >= self.cut:\n",
    "            if self.label is None:\n",
    "                return waveform[:self.cut], sample_rate\n",
    "            else:\n",
    "                return waveform[:self.cut], sample_rate, self.label\n",
    "        # need to pad\n",
    "        num_repeats = int(self.cut / waveform_len)+1\n",
    "        padded_waveform = torch.tile(waveform, (1, num_repeats))[\n",
    "            :, :self.cut][0]\n",
    "\n",
    "        if self.label is None:\n",
    "            return padded_waveform, sample_rate\n",
    "        else:\n",
    "            return padded_waveform, sample_rate, self.label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "def load_dataset(\n",
    "        path: Union[Path, str],\n",
    "        pad: bool = False,\n",
    "        train: str = 'train',\n",
    "        real: str = 'real',\n",
    "        label: Optional[int] = None,\n",
    "        max_samples_per_class: Optional[int] = None,  # new argument\n",
    ") -> torch.utils.data.Dataset:\n",
    "\n",
    "    cur_path = f\"{path}/{train}/{real}\"\n",
    "    paths = find_wav_files(cur_path)\n",
    "    if paths is None:\n",
    "        raise IOError(f\"No files found in {cur_path}\")\n",
    "\n",
    "    # Subsample to max_samples_per_class if given\n",
    "    if max_samples_per_class is not None and len(paths) > max_samples_per_class:\n",
    "        paths = random.sample(paths, max_samples_per_class)\n",
    "\n",
    "    LOGGER.info(f\"Loading {len(paths)} samples from {cur_path}\")\n",
    "\n",
    "    dataset = AudioDataset(paths)\n",
    "    if pad:\n",
    "        dataset = PadDataset(dataset, label=label)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-Related Code\n",
    "\n",
    "**RawNet**: RawNet2 code\n",
    "\n",
    "__init__: Creates the structure\n",
    "\n",
    "__forward__: Performs forward propagation. For the input audio signal x, softmax() is used to calculate the probability of fake/real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T13:50:46.534873Z",
     "iopub.status.busy": "2025-09-30T13:50:46.534466Z",
     "iopub.status.idle": "2025-09-30T13:50:46.567690Z",
     "shell.execute_reply": "2025-09-30T13:50:46.566669Z",
     "shell.execute_reply.started": "2025-09-30T13:50:46.534843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# raw_Net2\n",
    "\n",
    "class SincConv(nn.Module):\n",
    "    @staticmethod\n",
    "    def to_mel(hz):\n",
    "        return 2595 * np.log10(1 + hz / 700)\n",
    "\n",
    "    @staticmethod\n",
    "    def to_hz(mel):\n",
    "        return 700 * (10 ** (mel / 2595) - 1)\n",
    "\n",
    "\n",
    "    def __init__(self, device,out_channels, kernel_size,in_channels=1,sample_rate=16000,\n",
    "                 stride=1, padding=0, dilation=1, bias=False, groups=1):\n",
    "\n",
    "        super(SincConv,self).__init__()\n",
    "\n",
    "        if in_channels != 1:\n",
    "            \n",
    "            msg = \"SincConv only support one input channel (here, in_channels = {%i})\" % (in_channels)\n",
    "            raise ValueError(msg)\n",
    "        \n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate=sample_rate\n",
    "\n",
    "        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
    "        if kernel_size%2==0:\n",
    "            self.kernel_size=self.kernel_size+1\n",
    "\n",
    "        self.device=device   \n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        \n",
    "        if bias:\n",
    "            raise ValueError('SincConv does not support bias.')\n",
    "        if groups > 1:\n",
    "            raise ValueError('SincConv does not support groups.')\n",
    "        \n",
    "        \n",
    "        # initialize filterbanks using Mel scale\n",
    "        NFFT = 512\n",
    "        f=int(self.sample_rate/2)*np.linspace(0,1,int(NFFT/2)+1)\n",
    "        fmel=self.to_mel(f)   # Hz to mel conversion\n",
    "        fmelmax=np.max(fmel)\n",
    "        fmelmin=np.min(fmel)\n",
    "        filbandwidthsmel=np.linspace(fmelmin,fmelmax,self.out_channels+1)\n",
    "        filbandwidthsf=self.to_hz(filbandwidthsmel)  # Mel to Hz conversion\n",
    "        self.mel=filbandwidthsf\n",
    "        self.hsupp=torch.arange(-(self.kernel_size-1)/2, (self.kernel_size-1)/2+1)\n",
    "        self.band_pass=torch.zeros(self.out_channels,self.kernel_size)\n",
    "    \n",
    "       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        for i in range(len(self.mel)-1):\n",
    "            fmin=self.mel[i]\n",
    "            fmax=self.mel[i+1]\n",
    "            hHigh=(2*fmax/self.sample_rate)*np.sinc(2*fmax*self.hsupp/self.sample_rate)\n",
    "            hLow=(2*fmin/self.sample_rate)*np.sinc(2*fmin*self.hsupp/self.sample_rate)\n",
    "            hideal=hHigh-hLow\n",
    "            \n",
    "            self.band_pass[i,:]=Tensor(np.hamming(self.kernel_size))*Tensor(hideal)\n",
    "        \n",
    "        band_pass_filter=self.band_pass.to(self.device)\n",
    "\n",
    "        self.filters = (band_pass_filter).view(self.out_channels, 1, self.kernel_size)\n",
    "        \n",
    "        return F.conv1d(x, self.filters, stride=self.stride,\n",
    "                        padding=self.padding, dilation=self.dilation,\n",
    "                         bias=None, groups=1)\n",
    "\n",
    "\n",
    "        \n",
    "class Residual_block(nn.Module):\n",
    "    def __init__(self, nb_filts, first = False):\n",
    "        super(Residual_block, self).__init__()\n",
    "        self.first = first\n",
    "        \n",
    "        if not self.first:\n",
    "            self.bn1 = nn.BatchNorm1d(num_features = nb_filts[0])\n",
    "        \n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.3)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels = nb_filts[0],\n",
    "\t\t\tout_channels = nb_filts[1],\n",
    "\t\t\tkernel_size = 3,\n",
    "\t\t\tpadding = 1,\n",
    "\t\t\tstride = 1)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm1d(num_features = nb_filts[1])\n",
    "        self.conv2 = nn.Conv1d(in_channels = nb_filts[1],\n",
    "\t\t\tout_channels = nb_filts[1],\n",
    "\t\t\tpadding = 1,\n",
    "\t\t\tkernel_size = 3,\n",
    "\t\t\tstride = 1)\n",
    "        \n",
    "        if nb_filts[0] != nb_filts[1]:\n",
    "            self.downsample = True\n",
    "            self.conv_downsample = nn.Conv1d(in_channels = nb_filts[0],\n",
    "\t\t\t\tout_channels = nb_filts[1],\n",
    "\t\t\t\tpadding = 0,\n",
    "\t\t\t\tkernel_size = 1,\n",
    "\t\t\t\tstride = 1)\n",
    "            \n",
    "        else:\n",
    "            self.downsample = False\n",
    "        self.mp = nn.MaxPool1d(3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if not self.first:\n",
    "            out = self.bn1(x)\n",
    "            out = self.lrelu(out)\n",
    "        else:\n",
    "            out = x\n",
    "            \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn2(out)\n",
    "        out = self.lrelu(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            identity = self.conv_downsample(identity)\n",
    "            \n",
    "        out += identity\n",
    "        out = self.mp(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class RawNet(nn.Module):\n",
    "    def __init__(self, d_args, device):\n",
    "        super(RawNet, self).__init__()\n",
    "\n",
    "        \n",
    "        self.device=device\n",
    "\n",
    "        self.Sinc_conv=SincConv(device=self.device,\n",
    "\t\t\tout_channels = d_args['filts'][0],\n",
    "\t\t\tkernel_size = d_args['first_conv'],\n",
    "                        in_channels = d_args['in_channels']\n",
    "        )\n",
    "        \n",
    "        self.first_bn = nn.BatchNorm1d(num_features = d_args['filts'][0])\n",
    "        self.selu = nn.SELU(inplace=True)\n",
    "        self.block0 = Residual_block(nb_filts = d_args['filts'][1], first = True)\n",
    "        self.block1 = Residual_block(nb_filts = d_args['filts'][1])\n",
    "        self.block2 = Residual_block(nb_filts = d_args['filts'][2])\n",
    "        d_args['filts'][2][0] = d_args['filts'][2][1]\n",
    "        self.block3 = Residual_block(nb_filts = d_args['filts'][2])\n",
    "        self.block4 = Residual_block(nb_filts = d_args['filts'][2])\n",
    "        self.block5 = Residual_block(nb_filts = d_args['filts'][2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.fc_attention0 = self._make_attention_fc(in_features = d_args['filts'][1][-1],\n",
    "            l_out_features = d_args['filts'][1][-1])\n",
    "        self.fc_attention1 = self._make_attention_fc(in_features = d_args['filts'][1][-1],\n",
    "            l_out_features = d_args['filts'][1][-1])\n",
    "        self.fc_attention2 = self._make_attention_fc(in_features = d_args['filts'][2][-1],\n",
    "            l_out_features = d_args['filts'][2][-1])\n",
    "        self.fc_attention3 = self._make_attention_fc(in_features = d_args['filts'][2][-1],\n",
    "            l_out_features = d_args['filts'][2][-1])\n",
    "        self.fc_attention4 = self._make_attention_fc(in_features = d_args['filts'][2][-1],\n",
    "            l_out_features = d_args['filts'][2][-1])\n",
    "        self.fc_attention5 = self._make_attention_fc(in_features = d_args['filts'][2][-1],\n",
    "            l_out_features = d_args['filts'][2][-1])\n",
    "\n",
    "        self.bn_before_gru = nn.BatchNorm1d(num_features = d_args['filts'][2][-1])\n",
    "        self.gru = nn.GRU(input_size = d_args['filts'][2][-1],\n",
    "\t\t\thidden_size = d_args['gru_node'],\n",
    "\t\t\tnum_layers = d_args['nb_gru_layer'],\n",
    "\t\t\tbatch_first = True)\n",
    "\n",
    "        \n",
    "        self.fc1_gru = nn.Linear(in_features = d_args['gru_node'],\n",
    "\t\t\tout_features = d_args['nb_fc_node'])\n",
    "       \n",
    "        self.fc2_gru = nn.Linear(in_features = d_args['nb_fc_node'],\n",
    "\t\t\tout_features = d_args['nb_classes'],bias=True)\n",
    "\t\t\t\n",
    "       \n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, y = None):\n",
    "        \n",
    "        \n",
    "        nb_samp = x.shape[0]\n",
    "        len_seq = x.shape[1]\n",
    "        x=x.view(nb_samp,1,len_seq)\n",
    "        \n",
    "        x = self.Sinc_conv(x)    \n",
    "        x = F.max_pool1d(torch.abs(x), 3)\n",
    "        x = self.first_bn(x)\n",
    "        x =  self.selu(x)\n",
    "        \n",
    "        x0 = self.block0(x)\n",
    "        y0 = self.avgpool(x0).view(x0.size(0), -1) # torch.Size([batch, filter])\n",
    "        y0 = self.fc_attention0(y0)\n",
    "        y0 = self.sig(y0).view(y0.size(0), y0.size(1), -1)  # torch.Size([batch, filter, 1])\n",
    "        x = x0 * y0 + y0  # (batch, filter, time) x (batch, filter, 1)\n",
    "        \n",
    "\n",
    "        x1 = self.block1(x)\n",
    "        y1 = self.avgpool(x1).view(x1.size(0), -1) # torch.Size([batch, filter])\n",
    "        y1 = self.fc_attention1(y1)\n",
    "        y1 = self.sig(y1).view(y1.size(0), y1.size(1), -1)  # torch.Size([batch, filter, 1])\n",
    "        x = x1 * y1 + y1 # (batch, filter, time) x (batch, filter, 1)\n",
    "\n",
    "        x2 = self.block2(x)\n",
    "        y2 = self.avgpool(x2).view(x2.size(0), -1) # torch.Size([batch, filter])\n",
    "        y2 = self.fc_attention2(y2)\n",
    "        y2 = self.sig(y2).view(y2.size(0), y2.size(1), -1)  # torch.Size([batch, filter, 1])\n",
    "        x = x2 * y2 + y2 # (batch, filter, time) x (batch, filter, 1)\n",
    "\n",
    "        x3 = self.block3(x)\n",
    "        y3 = self.avgpool(x3).view(x3.size(0), -1) # torch.Size([batch, filter])\n",
    "        y3 = self.fc_attention3(y3)\n",
    "        y3 = self.sig(y3).view(y3.size(0), y3.size(1), -1)  # torch.Size([batch, filter, 1])\n",
    "        x = x3 * y3 + y3 # (batch, filter, time) x (batch, filter, 1)\n",
    "\n",
    "        x4 = self.block4(x)\n",
    "        y4 = self.avgpool(x4).view(x4.size(0), -1) # torch.Size([batch, filter])\n",
    "        y4 = self.fc_attention4(y4)\n",
    "        y4 = self.sig(y4).view(y4.size(0), y4.size(1), -1)  # torch.Size([batch, filter, 1])\n",
    "        x = x4 * y4 + y4 # (batch, filter, time) x (batch, filter, 1)\n",
    "\n",
    "        x5 = self.block5(x)\n",
    "        y5 = self.avgpool(x5).view(x5.size(0), -1) # torch.Size([batch, filter])\n",
    "        y5 = self.fc_attention5(y5)\n",
    "        y5 = self.sig(y5).view(y5.size(0), y5.size(1), -1)  # torch.Size([batch, filter, 1])\n",
    "        x = x5 * y5 + y5 # (batch, filter, time) x (batch, filter, 1)\n",
    "\n",
    "        x = self.bn_before_gru(x)\n",
    "        x = self.selu(x)\n",
    "        x = x.permute(0, 2, 1)     #(batch, filt, time) >> (batch, time, filt)\n",
    "        self.gru.flatten_parameters()\n",
    "        x, _ = self.gru(x)\n",
    "        x = x[:,-1,:]\n",
    "        x = self.fc1_gru(x)\n",
    "        x = self.fc2_gru(x).softmax(dim=1)\n",
    "        output = x\n",
    "        return output\n",
    "\n",
    "\n",
    "    def _make_attention_fc(self, in_features, l_out_features):\n",
    "        l_fc = []\n",
    "        l_fc.append(nn.Linear(in_features = in_features,\n",
    "\t\t\t        out_features = l_out_features))\n",
    "        return nn.Sequential(*l_fc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training-related code\n",
    "\n",
    "**GDTrainer**\n",
    "\n",
    "train\n",
    "\n",
    "Creates training and validation data loaders\n",
    "\n",
    "The loss function uses cross entropy.\n",
    "\n",
    "The optimizer uses Adam.\n",
    "\n",
    "Includes training and validation details for each epoch: After each epoch of training is completed, validation is performed and the accuracy for each epoch is calculated.\n",
    "\n",
    "test\n",
    "\n",
    "Loads the model with the highest validation accuracy and performs testing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T13:50:49.669202Z",
     "iopub.status.busy": "2025-09-30T13:50:49.668231Z",
     "iopub.status.idle": "2025-09-30T13:50:49.685289Z",
     "shell.execute_reply": "2025-09-30T13:50:49.684182Z",
     "shell.execute_reply.started": "2025-09-30T13:50:49.669170Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self,\n",
    "                 epochs: int = 20,\n",
    "                 batch_size: int = 16,\n",
    "                 device: str = \"cpu\",\n",
    "                 optimizer_fn: Callable = torch.optim.Adam,\n",
    "                 optimizer_kwargs: dict = {\"lr\": 1e-3},\n",
    "                 ) -> None:\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.optimizer_fn = optimizer_fn\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "        self.epoch_test_losses: List[float] = []\n",
    "\n",
    "\n",
    "\n",
    "class GDTrainer(Trainer):\n",
    "    def train(self,\n",
    "              dataset_train: torch.utils.data.Dataset,\n",
    "              dataset_validation: torch.utils.data.Dataset,\n",
    "              model: torch.nn.Module,\n",
    "              model_dir: str,\n",
    "              ):\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            dataset_train, batch_size=self.batch_size, shuffle=True, drop_last=True, num_workers=4)\n",
    "        validation_loader = DataLoader(\n",
    "            dataset_validation, batch_size=self.batch_size, drop_last=True, num_workers=4)\n",
    "\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optim = self.optimizer_fn(model.parameters(), **self.optimizer_kwargs)\n",
    "\n",
    "        best_model = None\n",
    "        best_acc = 0\n",
    "        for epoch in range(self.epochs):\n",
    "            running_loss = 0\n",
    "            num_correct = 0.0\n",
    "            num_total = 0.0\n",
    "            model.train()\n",
    "\n",
    "            for i, (batch_x, _, batch_y) in enumerate(train_loader):\n",
    "                batch_size = batch_x.size(0)\n",
    "                num_total += batch_size\n",
    "\n",
    "                batch_x = batch_x.to(self.device)\n",
    "                batch_y = batch_y.to(self.device)\n",
    "\n",
    "                batch_out = model(batch_x)\n",
    "                batch_loss = criterion(batch_out, batch_y)\n",
    "\n",
    "                _, batch_pred = batch_out.max(dim=1)\n",
    "                num_correct += (batch_pred == batch_y).sum(dim=0).item()\n",
    "\n",
    "\n",
    "                running_loss += (batch_loss.item() * batch_size)\n",
    "                \n",
    "                if i % (train_loader.__len__() // 20) == 0:\n",
    "                    cur_loss = batch_loss\n",
    "                    LOGGER.info(f\"[{epoch:04d}] {i}/{train_loader.__len__()}: {cur_loss}\")\n",
    "\n",
    "                optim.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "            running_loss /= num_total\n",
    "            train_accuracy = (num_correct/num_total)*100\n",
    "            \n",
    "            \n",
    "            num_correct = 0.0\n",
    "            num_total = 0.0\n",
    "            model.eval()\n",
    "            for batch_x, _, batch_y in validation_loader:\n",
    "\n",
    "                batch_size = batch_x.size(0)\n",
    "                num_total += batch_size\n",
    "                batch_x = batch_x.to(self.device)\n",
    "                batch_y = batch_y.to(self.device)\n",
    "\n",
    "                batch_out = model(batch_x)\n",
    "\n",
    "                _, batch_pred = batch_out.max(dim=1)\n",
    "                num_correct += (batch_pred == batch_y).sum(dim=0).item()\n",
    "\n",
    "            valid_acc = 100 * (num_correct / num_total)\n",
    "\n",
    "            if best_model is None or valid_acc > best_acc:\n",
    "                best_acc = valid_acc\n",
    "                best_model = deepcopy(model.state_dict())\n",
    "                save_model(model, model_dir,epoch)\n",
    "\n",
    "            LOGGER.info(\n",
    "                f\"[{epoch:04d}]: {running_loss} - train acc: {train_accuracy} - valid_acc: {valid_acc}\")\n",
    "\n",
    "        model.load_state_dict(best_model)\n",
    "        return model\n",
    "    \n",
    "    def test(self,\n",
    "              dataset_test: torch.utils.data.Dataset,\n",
    "              model: torch.nn.Module,\n",
    "              ):\n",
    "        model.eval()\n",
    "        test_loader = DataLoader(\n",
    "            dataset_test, batch_size=1, drop_last=False)\n",
    "        \n",
    "        f = open('submission.csv', 'w', newline='')\n",
    "        wr = csv.writer(f)\n",
    "        wr.writerow(['Id', 'Predicted'])\n",
    "\n",
    "        for i, (batch_x, _, batch_y) in enumerate(test_loader):\n",
    "                batch_x = batch_x.to(self.device)\n",
    "                batch_y = batch_y.to(self.device)\n",
    "                batch_out = model(batch_x)\n",
    "\n",
    "                _, batch_pred = batch_out.max(dim=1)\n",
    "\n",
    "                wr.writerow([i+1, batch_pred[0].item()])\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T13:51:04.816592Z",
     "iopub.status.busy": "2025-09-30T13:51:04.816224Z",
     "iopub.status.idle": "2025-09-30T13:51:04.830796Z",
     "shell.execute_reply": "2025-09-30T13:51:04.829550Z",
     "shell.execute_reply.started": "2025-09-30T13:51:04.816563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T13:54:45.776267Z",
     "iopub.status.busy": "2025-09-30T13:54:45.775356Z",
     "iopub.status.idle": "2025-09-30T14:44:39.822887Z",
     "shell.execute_reply": "2025-09-30T14:44:39.821382Z",
     "shell.execute_reply.started": "2025-09-30T13:54:45.776234Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:54:45,795 - INFO - Loading datasets...\n",
      "2025-09-30 13:55:07,349 - INFO - Loading 10000 samples from /kaggle/input/2024-jbnu-competition-revised/train/real\n",
      "2025-09-30 13:57:19,029 - INFO - Loading 10000 samples from /kaggle/input/2024-jbnu-competition-revised/train/fake\n",
      "2025-09-30 13:57:24,867 - INFO - Loading 3000 samples from /kaggle/input/2024-jbnu-competition-revised/validation/real\n",
      "2025-09-30 13:58:05,127 - INFO - Loading 3000 samples from /kaggle/input/2024-jbnu-competition-revised/validation/fake\n",
      "2025-09-30 13:59:27,682 - INFO - Train samples: 20000 | Validation samples: 6000 | Test samples: 1000\n",
      "2025-09-30 13:59:27,865 - INFO - RawNet model initialized.\n",
      "2025-09-30 13:59:28,749 - INFO - [0000] 0/1250: 0.6911762952804565\n",
      "2025-09-30 13:59:39,198 - INFO - [0000] 62/1250: 0.750761866569519\n",
      "2025-09-30 13:59:49,459 - INFO - [0000] 124/1250: 0.8132619261741638\n",
      "2025-09-30 13:59:59,123 - INFO - [0000] 186/1250: 0.7507619261741638\n",
      "2025-09-30 14:00:08,992 - INFO - [0000] 248/1250: 0.813261866569519\n",
      "2025-09-30 14:00:18,824 - INFO - [0000] 310/1250: 0.688261866569519\n",
      "2025-09-30 14:00:28,320 - INFO - [0000] 372/1250: 0.8132619261741638\n",
      "2025-09-30 14:00:38,055 - INFO - [0000] 434/1250: 0.563261866569519\n",
      "2025-09-30 14:00:47,700 - INFO - [0000] 496/1250: 0.8757619261741638\n",
      "2025-09-30 14:00:57,429 - INFO - [0000] 558/1250: 0.750761866569519\n",
      "2025-09-30 14:01:07,021 - INFO - [0000] 620/1250: 1.063261866569519\n",
      "2025-09-30 14:01:32,281 - INFO - [0000] 682/1250: 0.625761866569519\n",
      "2025-09-30 14:01:42,101 - INFO - [0000] 744/1250: 0.813261866569519\n",
      "2025-09-30 14:01:51,636 - INFO - [0000] 806/1250: 1.2507617473602295\n",
      "2025-09-30 14:02:01,484 - INFO - [0000] 868/1250: 0.688261866569519\n",
      "2025-09-30 14:02:11,146 - INFO - [0000] 930/1250: 0.875761866569519\n",
      "2025-09-30 14:02:20,969 - INFO - [0000] 992/1250: 0.7507619261741638\n",
      "2025-09-30 14:02:30,661 - INFO - [0000] 1054/1250: 0.813261866569519\n",
      "2025-09-30 14:02:40,565 - INFO - [0000] 1116/1250: 0.8132619261741638\n",
      "2025-09-30 14:02:50,206 - INFO - [0000] 1178/1250: 0.813261866569519\n",
      "2025-09-30 14:03:00,145 - INFO - [0000] 1240/1250: 0.875761866569519\n",
      "2025-09-30 14:03:59,768 - INFO - Saved model to trained_models/model_epoch_1.pth\n",
      "2025-09-30 14:03:59,770 - INFO - [0000]: 0.7971658390045167 - train acc: 51.615 - valid_acc: 51.016666666666666\n",
      "2025-09-30 14:04:00,683 - INFO - [0001] 0/1250: 0.9382619261741638\n",
      "2025-09-30 14:04:11,232 - INFO - [0001] 62/1250: 1.000761866569519\n",
      "2025-09-30 14:04:21,237 - INFO - [0001] 124/1250: 0.8132619261741638\n",
      "2025-09-30 14:04:31,056 - INFO - [0001] 186/1250: 0.8757619261741638\n",
      "2025-09-30 14:04:40,648 - INFO - [0001] 248/1250: 0.688261866569519\n",
      "2025-09-30 14:04:50,454 - INFO - [0001] 310/1250: 0.8132619261741638\n",
      "2025-09-30 14:05:00,094 - INFO - [0001] 372/1250: 0.688261866569519\n",
      "2025-09-30 14:05:09,816 - INFO - [0001] 434/1250: 0.750761866569519\n",
      "2025-09-30 14:05:19,487 - INFO - [0001] 496/1250: 0.750761866569519\n",
      "2025-09-30 14:05:29,299 - INFO - [0001] 558/1250: 0.8132619261741638\n",
      "2025-09-30 14:05:38,919 - INFO - [0001] 620/1250: 0.8757619261741638\n",
      "2025-09-30 14:05:48,679 - INFO - [0001] 682/1250: 0.688261866569519\n",
      "2025-09-30 14:05:58,386 - INFO - [0001] 744/1250: 0.500761866569519\n",
      "2025-09-30 14:06:08,288 - INFO - [0001] 806/1250: 0.6882618069648743\n",
      "2025-09-30 14:06:17,971 - INFO - [0001] 868/1250: 1.000761866569519\n",
      "2025-09-30 14:06:27,790 - INFO - [0001] 930/1250: 0.625761866569519\n",
      "2025-09-30 14:06:37,321 - INFO - [0001] 992/1250: 0.688261866569519\n",
      "2025-09-30 14:06:47,086 - INFO - [0001] 1054/1250: 0.813261866569519\n",
      "2025-09-30 14:07:12,070 - INFO - [0001] 1116/1250: 0.8132619261741638\n",
      "2025-09-30 14:07:21,707 - INFO - [0001] 1178/1250: 0.9382619261741638\n",
      "2025-09-30 14:07:31,681 - INFO - [0001] 1240/1250: 0.750761866569519\n",
      "2025-09-30 14:08:30,950 - INFO - [0001]: 0.7973118871688842 - train acc: 51.595 - valid_acc: 50.61666666666667\n",
      "2025-09-30 14:08:31,830 - INFO - [0002] 0/1250: 0.7507619261741638\n",
      "2025-09-30 14:08:42,416 - INFO - [0002] 62/1250: 0.688261866569519\n",
      "2025-09-30 14:08:52,738 - INFO - [0002] 124/1250: 0.750761866569519\n",
      "2025-09-30 14:09:02,386 - INFO - [0002] 186/1250: 0.9382619261741638\n",
      "2025-09-30 14:09:12,279 - INFO - [0002] 248/1250: 0.813261866569519\n",
      "2025-09-30 14:09:21,825 - INFO - [0002] 310/1250: 0.688261866569519\n",
      "2025-09-30 14:09:31,564 - INFO - [0002] 372/1250: 0.750761866569519\n",
      "2025-09-30 14:09:41,356 - INFO - [0002] 434/1250: 1.000761866569519\n",
      "2025-09-30 14:09:51,157 - INFO - [0002] 496/1250: 0.9382619261741638\n",
      "2025-09-30 14:10:16,428 - INFO - [0002] 558/1250: 0.813261866569519\n",
      "2025-09-30 14:10:26,318 - INFO - [0002] 620/1250: 0.6882619261741638\n",
      "2025-09-30 14:10:35,884 - INFO - [0002] 682/1250: 0.813261866569519\n",
      "2025-09-30 14:10:45,794 - INFO - [0002] 744/1250: 0.9382619261741638\n",
      "2025-09-30 14:10:55,393 - INFO - [0002] 806/1250: 0.8132619261741638\n",
      "2025-09-30 14:11:05,399 - INFO - [0002] 868/1250: 0.750761866569519\n",
      "2025-09-30 14:11:15,087 - INFO - [0002] 930/1250: 1.000761866569519\n",
      "2025-09-30 14:11:24,863 - INFO - [0002] 992/1250: 0.688261866569519\n",
      "2025-09-30 14:11:34,436 - INFO - [0002] 1054/1250: 0.563261866569519\n",
      "2025-09-30 14:11:44,259 - INFO - [0002] 1116/1250: 0.9382619261741638\n",
      "2025-09-30 14:11:53,832 - INFO - [0002] 1178/1250: 0.8757619261741638\n",
      "2025-09-30 14:12:03,679 - INFO - [0002] 1240/1250: 0.625761866569519\n",
      "2025-09-30 14:13:03,085 - INFO - Saved model to trained_models/model_epoch_3.pth\n",
      "2025-09-30 14:13:03,087 - INFO - [0002]: 0.8005118878364563 - train acc: 51.275000000000006 - valid_acc: 51.06666666666667\n",
      "2025-09-30 14:13:03,975 - INFO - [0003] 0/1250: 0.8132619261741638\n",
      "2025-09-30 14:13:14,498 - INFO - [0003] 62/1250: 0.813261866569519\n",
      "2025-09-30 14:13:24,647 - INFO - [0003] 124/1250: 0.688261866569519\n",
      "2025-09-30 14:13:34,318 - INFO - [0003] 186/1250: 0.625761866569519\n",
      "2025-09-30 14:13:44,168 - INFO - [0003] 248/1250: 1.000761866569519\n",
      "2025-09-30 14:13:53,790 - INFO - [0003] 310/1250: 0.688261866569519\n",
      "2025-09-30 14:14:03,687 - INFO - [0003] 372/1250: 0.8757619261741638\n",
      "2025-09-30 14:14:13,369 - INFO - [0003] 434/1250: 0.688261866569519\n",
      "2025-09-30 14:14:23,047 - INFO - [0003] 496/1250: 0.7507619261741638\n",
      "2025-09-30 14:14:32,672 - INFO - [0003] 558/1250: 0.8757619261741638\n",
      "2025-09-30 14:14:42,353 - INFO - [0003] 620/1250: 0.688261866569519\n",
      "2025-09-30 14:14:51,822 - INFO - [0003] 682/1250: 0.875761866569519\n",
      "2025-09-30 14:15:01,747 - INFO - [0003] 744/1250: 0.8132619261741638\n",
      "2025-09-30 14:15:11,430 - INFO - [0003] 806/1250: 0.688261866569519\n",
      "2025-09-30 14:15:36,553 - INFO - [0003] 868/1250: 0.813261866569519\n",
      "2025-09-30 14:15:46,397 - INFO - [0003] 930/1250: 0.8757619261741638\n",
      "2025-09-30 14:15:55,917 - INFO - [0003] 992/1250: 0.9382619261741638\n",
      "2025-09-30 14:16:05,779 - INFO - [0003] 1054/1250: 0.625761866569519\n",
      "2025-09-30 14:16:15,413 - INFO - [0003] 1116/1250: 0.688261866569519\n",
      "2025-09-30 14:16:25,290 - INFO - [0003] 1178/1250: 0.7507619261741638\n",
      "2025-09-30 14:16:34,764 - INFO - [0003] 1240/1250: 0.750761866569519\n",
      "2025-09-30 14:17:33,764 - INFO - [0003]: 0.7978618879318238 - train acc: 51.54 - valid_acc: 50.93333333333333\n",
      "2025-09-30 14:17:34,765 - INFO - [0004] 0/1250: 0.8757619261741638\n",
      "2025-09-30 14:17:45,149 - INFO - [0004] 62/1250: 0.8757619261741638\n",
      "2025-09-30 14:17:55,347 - INFO - [0004] 124/1250: 0.8132619261741638\n",
      "2025-09-30 14:18:05,260 - INFO - [0004] 186/1250: 0.6882619261741638\n",
      "2025-09-30 14:18:15,315 - INFO - [0004] 248/1250: 0.8757619261741638\n",
      "2025-09-30 14:18:24,845 - INFO - [0004] 310/1250: 0.625761866569519\n",
      "2025-09-30 14:18:34,568 - INFO - [0004] 372/1250: 0.688261866569519\n",
      "2025-09-30 14:18:44,224 - INFO - [0004] 434/1250: 0.8757619261741638\n",
      "2025-09-30 14:18:54,076 - INFO - [0004] 496/1250: 0.8132619261741638\n",
      "2025-09-30 14:19:03,740 - INFO - [0004] 558/1250: 0.9382619261741638\n",
      "2025-09-30 14:19:13,529 - INFO - [0004] 620/1250: 0.8757619261741638\n",
      "2025-09-30 14:19:22,979 - INFO - [0004] 682/1250: 0.8757619261741638\n",
      "2025-09-30 14:19:32,696 - INFO - [0004] 744/1250: 0.7507618069648743\n",
      "2025-09-30 14:19:42,145 - INFO - [0004] 806/1250: 0.8132619261741638\n",
      "2025-09-30 14:19:51,763 - INFO - [0004] 868/1250: 0.8132619261741638\n",
      "2025-09-30 14:20:01,424 - INFO - [0004] 930/1250: 0.43826186656951904\n",
      "2025-09-30 14:20:11,230 - INFO - [0004] 992/1250: 0.688261866569519\n",
      "2025-09-30 14:20:21,221 - INFO - [0004] 1054/1250: 0.750761866569519\n",
      "2025-09-30 14:20:46,428 - INFO - [0004] 1116/1250: 1.000761866569519\n",
      "2025-09-30 14:20:56,318 - INFO - [0004] 1178/1250: 0.8757619261741638\n",
      "2025-09-30 14:21:05,974 - INFO - [0004] 1240/1250: 0.9382619261741638\n",
      "2025-09-30 14:22:05,498 - INFO - Saved model to trained_models/model_epoch_5.pth\n",
      "2025-09-30 14:22:05,499 - INFO - [0004]: 0.7976118889331818 - train acc: 51.565000000000005 - valid_acc: 51.1\n",
      "2025-09-30 14:22:06,367 - INFO - [0005] 0/1250: 0.8132619261741638\n",
      "2025-09-30 14:22:16,798 - INFO - [0005] 62/1250: 1.1882617473602295\n",
      "2025-09-30 14:22:26,824 - INFO - [0005] 124/1250: 0.750761866569519\n",
      "2025-09-30 14:22:36,513 - INFO - [0005] 186/1250: 0.813261866569519\n",
      "2025-09-30 14:22:46,106 - INFO - [0005] 248/1250: 0.8132619261741638\n",
      "2025-09-30 14:22:55,925 - INFO - [0005] 310/1250: 0.875761866569519\n",
      "2025-09-30 14:23:05,422 - INFO - [0005] 372/1250: 0.938261866569519\n",
      "2025-09-30 14:23:15,492 - INFO - [0005] 434/1250: 0.750761866569519\n",
      "2025-09-30 14:23:25,150 - INFO - [0005] 496/1250: 0.8132619261741638\n",
      "2025-09-30 14:23:35,091 - INFO - [0005] 558/1250: 0.9382619261741638\n",
      "2025-09-30 14:23:44,601 - INFO - [0005] 620/1250: 0.8757619261741638\n",
      "2025-09-30 14:23:54,384 - INFO - [0005] 682/1250: 0.875761866569519\n",
      "2025-09-30 14:24:03,916 - INFO - [0005] 744/1250: 1.000761866569519\n",
      "2025-09-30 14:24:13,721 - INFO - [0005] 806/1250: 0.938261866569519\n",
      "2025-09-30 14:24:23,377 - INFO - [0005] 868/1250: 0.750761866569519\n",
      "2025-09-30 14:24:33,208 - INFO - [0005] 930/1250: 0.625761866569519\n",
      "2025-09-30 14:24:58,049 - INFO - [0005] 992/1250: 0.813261866569519\n",
      "2025-09-30 14:25:08,072 - INFO - [0005] 1054/1250: 0.8757619261741638\n",
      "2025-09-30 14:25:17,865 - INFO - [0005] 1116/1250: 0.5632618069648743\n",
      "2025-09-30 14:25:27,591 - INFO - [0005] 1178/1250: 0.9382619261741638\n",
      "2025-09-30 14:25:37,555 - INFO - [0005] 1240/1250: 0.688261866569519\n",
      "2025-09-30 14:26:37,109 - INFO - Saved model to trained_models/model_epoch_6.pth\n",
      "2025-09-30 14:26:37,111 - INFO - [0005]: 0.7954618884563446 - train acc: 51.78 - valid_acc: 51.33333333333333\n",
      "2025-09-30 14:26:38,030 - INFO - [0006] 0/1250: 0.8757619261741638\n",
      "2025-09-30 14:26:48,467 - INFO - [0006] 62/1250: 0.8132619261741638\n",
      "2025-09-30 14:26:58,696 - INFO - [0006] 124/1250: 0.813261866569519\n",
      "2025-09-30 14:27:08,466 - INFO - [0006] 186/1250: 0.688261866569519\n",
      "2025-09-30 14:27:18,069 - INFO - [0006] 248/1250: 0.7507619261741638\n",
      "2025-09-30 14:27:27,638 - INFO - [0006] 310/1250: 0.8132619261741638\n",
      "2025-09-30 14:27:37,455 - INFO - [0006] 372/1250: 0.7507619261741638\n",
      "2025-09-30 14:27:47,084 - INFO - [0006] 434/1250: 0.5007618069648743\n",
      "2025-09-30 14:27:56,749 - INFO - [0006] 496/1250: 0.8132619261741638\n",
      "2025-09-30 14:28:06,318 - INFO - [0006] 558/1250: 0.8757619261741638\n",
      "2025-09-30 14:28:16,140 - INFO - [0006] 620/1250: 0.750761866569519\n",
      "2025-09-30 14:28:25,719 - INFO - [0006] 682/1250: 0.688261866569519\n",
      "2025-09-30 14:28:35,470 - INFO - [0006] 744/1250: 0.688261866569519\n",
      "2025-09-30 14:28:44,922 - INFO - [0006] 806/1250: 0.8132619261741638\n",
      "2025-09-30 14:29:10,086 - INFO - [0006] 868/1250: 0.8757619261741638\n",
      "2025-09-30 14:29:19,876 - INFO - [0006] 930/1250: 0.8132619261741638\n",
      "2025-09-30 14:29:29,511 - INFO - [0006] 992/1250: 0.750761866569519\n",
      "2025-09-30 14:29:39,352 - INFO - [0006] 1054/1250: 0.750761866569519\n",
      "2025-09-30 14:29:49,127 - INFO - [0006] 1116/1250: 0.8757619261741638\n",
      "2025-09-30 14:29:59,106 - INFO - [0006] 1178/1250: 0.8132619261741638\n",
      "2025-09-30 14:30:09,106 - INFO - [0006] 1240/1250: 0.8132619261741638\n",
      "2025-09-30 14:31:08,300 - INFO - [0006]: 0.7945618873596192 - train acc: 51.870000000000005 - valid_acc: 50.916666666666664\n",
      "2025-09-30 14:31:09,222 - INFO - [0007] 0/1250: 0.500761866569519\n",
      "2025-09-30 14:31:19,389 - INFO - [0007] 62/1250: 0.813261866569519\n",
      "2025-09-30 14:31:29,401 - INFO - [0007] 124/1250: 0.750761866569519\n",
      "2025-09-30 14:31:39,301 - INFO - [0007] 186/1250: 1.063261866569519\n",
      "2025-09-30 14:31:48,984 - INFO - [0007] 248/1250: 0.813261866569519\n",
      "2025-09-30 14:31:58,770 - INFO - [0007] 310/1250: 0.688261866569519\n",
      "2025-09-30 14:32:08,287 - INFO - [0007] 372/1250: 0.625761866569519\n",
      "2025-09-30 14:32:17,977 - INFO - [0007] 434/1250: 0.750761866569519\n",
      "2025-09-30 14:32:42,833 - INFO - [0007] 496/1250: 0.8132619261741638\n",
      "2025-09-30 14:32:52,695 - INFO - [0007] 558/1250: 0.813261866569519\n",
      "2025-09-30 14:33:02,275 - INFO - [0007] 620/1250: 0.8132619261741638\n",
      "2025-09-30 14:33:11,976 - INFO - [0007] 682/1250: 0.8757619261741638\n",
      "2025-09-30 14:33:21,606 - INFO - [0007] 744/1250: 1.000761866569519\n",
      "2025-09-30 14:33:31,398 - INFO - [0007] 806/1250: 0.8757619261741638\n",
      "2025-09-30 14:33:41,009 - INFO - [0007] 868/1250: 0.688261866569519\n",
      "2025-09-30 14:33:50,603 - INFO - [0007] 930/1250: 0.875761866569519\n",
      "2025-09-30 14:34:00,292 - INFO - [0007] 992/1250: 0.813261866569519\n",
      "2025-09-30 14:34:10,191 - INFO - [0007] 1054/1250: 0.8132619261741638\n",
      "2025-09-30 14:34:19,830 - INFO - [0007] 1116/1250: 0.625761866569519\n",
      "2025-09-30 14:34:29,713 - INFO - [0007] 1178/1250: 0.750761866569519\n",
      "2025-09-30 14:34:39,343 - INFO - [0007] 1240/1250: 0.813261866569519\n",
      "2025-09-30 14:35:38,815 - INFO - Saved model to trained_models/model_epoch_8.pth\n",
      "2025-09-30 14:35:38,817 - INFO - [0007]: 0.7991118878364563 - train acc: 51.415 - valid_acc: 51.63333333333333\n",
      "2025-09-30 14:35:39,766 - INFO - [0008] 0/1250: 1.000761866569519\n",
      "2025-09-30 14:35:49,969 - INFO - [0008] 62/1250: 0.938261866569519\n",
      "2025-09-30 14:35:59,820 - INFO - [0008] 124/1250: 0.9382619261741638\n",
      "2025-09-30 14:36:09,842 - INFO - [0008] 186/1250: 0.8132619261741638\n",
      "2025-09-30 14:36:19,441 - INFO - [0008] 248/1250: 0.688261866569519\n",
      "2025-09-30 14:36:29,124 - INFO - [0008] 310/1250: 0.9382619261741638\n",
      "2025-09-30 14:36:53,599 - INFO - [0008] 372/1250: 0.750761866569519\n",
      "2025-09-30 14:37:03,332 - INFO - [0008] 434/1250: 0.750761866569519\n",
      "2025-09-30 14:37:12,993 - INFO - [0008] 496/1250: 1.063261866569519\n",
      "2025-09-30 14:37:22,798 - INFO - [0008] 558/1250: 0.688261866569519\n",
      "2025-09-30 14:37:32,361 - INFO - [0008] 620/1250: 0.8757619261741638\n",
      "2025-09-30 14:37:42,322 - INFO - [0008] 682/1250: 0.688261866569519\n",
      "2025-09-30 14:37:52,004 - INFO - [0008] 744/1250: 0.625761866569519\n",
      "2025-09-30 14:38:01,862 - INFO - [0008] 806/1250: 0.688261866569519\n",
      "2025-09-30 14:38:11,494 - INFO - [0008] 868/1250: 0.688261866569519\n",
      "2025-09-30 14:38:21,457 - INFO - [0008] 930/1250: 0.563261866569519\n",
      "2025-09-30 14:38:30,974 - INFO - [0008] 992/1250: 0.750761866569519\n",
      "2025-09-30 14:38:40,974 - INFO - [0008] 1054/1250: 0.750761866569519\n",
      "2025-09-30 14:38:50,498 - INFO - [0008] 1116/1250: 0.938261866569519\n",
      "2025-09-30 14:39:00,508 - INFO - [0008] 1178/1250: 0.875761866569519\n",
      "2025-09-30 14:39:09,943 - INFO - [0008] 1240/1250: 0.688261866569519\n",
      "2025-09-30 14:40:09,197 - INFO - [0008]: 0.7968618877410889 - train acc: 51.64 - valid_acc: 50.71666666666667\n",
      "2025-09-30 14:40:10,128 - INFO - [0009] 0/1250: 0.8757619261741638\n",
      "2025-09-30 14:40:20,431 - INFO - [0009] 62/1250: 0.625761866569519\n",
      "2025-09-30 14:40:30,603 - INFO - [0009] 124/1250: 0.875761866569519\n",
      "2025-09-30 14:40:40,257 - INFO - [0009] 186/1250: 1.063261866569519\n",
      "2025-09-30 14:40:50,002 - INFO - [0009] 248/1250: 0.9382619261741638\n",
      "2025-09-30 14:41:15,033 - INFO - [0009] 310/1250: 0.875761866569519\n",
      "2025-09-30 14:41:24,915 - INFO - [0009] 372/1250: 0.8132619261741638\n",
      "2025-09-30 14:41:34,418 - INFO - [0009] 434/1250: 0.875761866569519\n",
      "2025-09-30 14:41:44,174 - INFO - [0009] 496/1250: 0.9382619261741638\n",
      "2025-09-30 14:41:53,621 - INFO - [0009] 558/1250: 0.9382619261741638\n",
      "2025-09-30 14:42:03,392 - INFO - [0009] 620/1250: 0.8132619261741638\n",
      "2025-09-30 14:42:12,939 - INFO - [0009] 682/1250: 1.063261866569519\n",
      "2025-09-30 14:42:22,780 - INFO - [0009] 744/1250: 0.9382619261741638\n",
      "2025-09-30 14:42:32,394 - INFO - [0009] 806/1250: 0.750761866569519\n",
      "2025-09-30 14:42:42,187 - INFO - [0009] 868/1250: 0.813261866569519\n",
      "2025-09-30 14:42:51,788 - INFO - [0009] 930/1250: 0.625761866569519\n",
      "2025-09-30 14:43:01,577 - INFO - [0009] 992/1250: 0.688261866569519\n",
      "2025-09-30 14:43:11,427 - INFO - [0009] 1054/1250: 0.9382619261741638\n",
      "2025-09-30 14:43:21,433 - INFO - [0009] 1116/1250: 0.9382619261741638\n",
      "2025-09-30 14:43:31,034 - INFO - [0009] 1178/1250: 0.9382619261741638\n",
      "2025-09-30 14:43:40,826 - INFO - [0009] 1240/1250: 0.5007618069648743\n",
      "2025-09-30 14:44:39,713 - INFO - [0009]: 0.795511887216568 - train acc: 51.775000000000006 - valid_acc: 51.6\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable RawNet object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 148\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: model,\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m: train_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_val_accuracies\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch_val_accuracies\n\u001b[1;32m    145\u001b[0m     })\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 148\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[40], line 124\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m model_dir\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# --- TRAIN MODEL ---\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m model, train_dataset, val_dataset, test_dataset, epoch_train_losses, epoch_val_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_raw_net\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_train_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_val_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_test_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m     \u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Save variables globally if needed\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mglobals\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: model,\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m: train_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_val_accuracies\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch_val_accuracies\n\u001b[1;32m    145\u001b[0m })\n",
      "Cell \u001b[0;32mIn[40], line 94\u001b[0m, in \u001b[0;36mtrain_raw_net\u001b[0;34m(base_dir, test_dir, batch_size, epochs, device, model_dir, max_train_samples, max_val_samples, max_test_samples)\u001b[0m\n\u001b[1;32m     91\u001b[0m trainer \u001b[38;5;241m=\u001b[39m GDTrainer(batch_size\u001b[38;5;241m=\u001b[39mbatch_size, device\u001b[38;5;241m=\u001b[39mdevice, epochs\u001b[38;5;241m=\u001b[39mepochs)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# --- MODIFIED: capture epoch-wise metrics ---\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m model, epoch_train_losses, epoch_val_accuracies \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m     95\u001b[0m     dataset_train\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     96\u001b[0m     dataset_validation\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[1;32m     97\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     98\u001b[0m     model_dir\u001b[38;5;241m=\u001b[39mmodel_dir\n\u001b[1;32m     99\u001b[0m )\n\u001b[1;32m    101\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, train_dataset, val_dataset, test_dataset, epoch_train_losses, epoch_val_accuracies\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable RawNet object"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset\n",
    "from copy import deepcopy\n",
    "from typing import Union\n",
    "\n",
    "# ---------------------------\n",
    "# Logger\n",
    "# ---------------------------\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "def init_logger(log_file=\"experiments.log\"):\n",
    "    LOGGER.setLevel(logging.INFO)\n",
    "    fh = logging.FileHandler(log_file)\n",
    "    ch = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    fh.setFormatter(formatter)\n",
    "    ch.setFormatter(formatter)\n",
    "    if not LOGGER.handlers:\n",
    "        LOGGER.addHandler(fh)\n",
    "        LOGGER.addHandler(ch)\n",
    "\n",
    "# ---------------------------\n",
    "# RawNet config\n",
    "# ---------------------------\n",
    "RAW_NET_CONFIG = {\n",
    "    \"nb_samp\": 64600,\n",
    "    \"first_conv\": 1024,\n",
    "    \"in_channels\": 1,\n",
    "    \"filts\": [20, [20, 20], [20, 128], [128, 128]],\n",
    "    \"blocks\": [2, 4],\n",
    "    \"nb_fc_node\": 1024,\n",
    "    \"gru_node\": 1024,\n",
    "    \"nb_gru_layer\": 3,\n",
    "    \"nb_classes\": 2,\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# Test dataset loader\n",
    "# ---------------------------\n",
    "def load_dataset_test(path: Union[Path, str], pad: bool = True):\n",
    "    paths = find_wav_files(path)\n",
    "    if paths is None:\n",
    "        raise IOError(f\"No files found in {path}!\")\n",
    "    dataset = AudioDataset(paths)\n",
    "    if pad:\n",
    "        dataset = PadDataset(dataset, label=None)\n",
    "    return dataset\n",
    "\n",
    "# ---------------------------\n",
    "# Training function\n",
    "# ---------------------------\n",
    "def train_raw_net(\n",
    "        base_dir: Union[Path, str],\n",
    "        test_dir: Union[Path, str],\n",
    "        batch_size: int = 16,\n",
    "        epochs: int = 3,\n",
    "        device: str = \"cuda\",\n",
    "        model_dir: Path = None,\n",
    "        max_train_samples: int = 1000,  \n",
    "        max_val_samples: int = 500,     \n",
    "        max_test_samples: int = 1000    \n",
    "):\n",
    "    LOGGER.info(\"Loading datasets...\")\n",
    "\n",
    "    # Balanced training datasets\n",
    "    real_train = load_dataset(base_dir, pad=True, train='train', real='real', label=1, max_samples_per_class=max_train_samples)\n",
    "    fake_train = load_dataset(base_dir, pad=True, train='train', real='fake', label=0, max_samples_per_class=max_train_samples)\n",
    "    train_dataset = ConcatDataset([real_train, fake_train])\n",
    "\n",
    "    real_val = load_dataset(base_dir, pad=True, train='validation', real='real', label=1, max_samples_per_class=max_val_samples)\n",
    "    fake_val = load_dataset(base_dir, pad=True, train='validation', real='fake', label=0, max_samples_per_class=max_val_samples)\n",
    "    val_dataset = ConcatDataset([real_val, fake_val])\n",
    "\n",
    "    # Test dataset (limited for quick testing)\n",
    "    full_test_dataset = load_dataset_test(test_dir, pad=True)\n",
    "    test_dataset = Subset(full_test_dataset, list(range(min(max_test_samples, len(full_test_dataset)))))\n",
    "\n",
    "    LOGGER.info(f\"Train samples: {len(train_dataset)} | Validation samples: {len(val_dataset)} | Test samples: {len(test_dataset)}\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # Initialize model\n",
    "    # ---------------------------\n",
    "    model = RawNet(deepcopy(RAW_NET_CONFIG), device).to(device)\n",
    "    LOGGER.info(\"RawNet model initialized.\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # Initialize trainer\n",
    "    # ---------------------------\n",
    "    trainer = GDTrainer(batch_size=batch_size, device=device, epochs=epochs)\n",
    "\n",
    "    # --- MODIFIED: capture epoch-wise metrics ---\n",
    "    model, epoch_train_losses, epoch_val_accuracies = trainer.train(\n",
    "        dataset_train=train_dataset,\n",
    "        dataset_validation=val_dataset,\n",
    "        model=model,\n",
    "        model_dir=model_dir\n",
    "    )\n",
    "\n",
    "    LOGGER.info(\"Training complete!\")\n",
    "\n",
    "    return model, train_dataset, val_dataset, test_dataset, epoch_train_losses, epoch_val_accuracies\n",
    "\n",
    "# ---------------------------\n",
    "# Main\n",
    "# ---------------------------\n",
    "def main():\n",
    "    set_seed(42)\n",
    "    init_logger()\n",
    "\n",
    "    device = \"cuda\"\n",
    "    base_dir = '/kaggle/input/2024-jbnu-competition-revised'\n",
    "    test_dir = '/kaggle/input/2024-jbnu-competition-revised/test'\n",
    "\n",
    "    batch_size = 16\n",
    "    epochs = 10\n",
    "\n",
    "    # Model directory\n",
    "    model_dir = Path(\"trained_models\")\n",
    "    model_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # --- TRAIN MODEL ---\n",
    "    model, train_dataset, val_dataset, test_dataset, epoch_train_losses, epoch_val_accuracies = train_raw_net(\n",
    "        base_dir=base_dir,\n",
    "        test_dir=test_dir,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        device=device,\n",
    "        model_dir=model_dir,\n",
    "        max_train_samples=10000,   \n",
    "        max_val_samples=3000,      \n",
    "        max_test_samples=1000     \n",
    "    )\n",
    "\n",
    "    # Save variables globally if needed\n",
    "    globals().update({\n",
    "        'model': model,\n",
    "        'train_dataset': train_dataset,\n",
    "        'val_dataset': val_dataset,\n",
    "        'test_dataset': test_dataset,\n",
    "        'device': device,\n",
    "        'epoch_train_losses': epoch_train_losses,\n",
    "        'epoch_val_accuracies': epoch_val_accuracies\n",
    "    })\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-30 14:44:37,795 - INFO - Loading datasets...\n",
      "2025-09-30 14:45:17,349 - INFO - Loading 10000 samples from /kaggle/input/2024-jbnu-competition-revised/train/real\n",
      "2025-09-30 14:47:28,029 - INFO - Loading 10000 samples from /kaggle/input/2024-jbnu-competition-revised/train/fake\n",
      "2025-09-30 14:47:26,867 - INFO - Loading 3000 samples from /kaggle/input/2024-jbnu-competition-revised/validation/real\n",
      "2025-09-30 14:48:45,127 - INFO - Loading 3000 samples from /kaggle/input/2024-jbnu-competition-revised/validation/fake\n",
      "2025-09-30 14:49:36,682 - INFO - Train samples: 20000 | Validation samples: 6000 | Test samples: 1000\n",
      "2025-09-30 14:50:39,865 - INFO - RawNet model initialized.\n",
      "2025-09-30 14:50:39,000 - INFO - [0000] 0/1250: 1.002471833\n",
      "2025-09-30 14:50:47,970 - INFO - [0000] 62/1250: 0.533623908\n",
      "2025-09-30 14:50:59,337 - INFO - [0000] 124/1250: 0.728589981\n",
      "2025-09-30 14:51:07,469 - INFO - [0000] 186/1250: 0.864080613\n",
      "2025-09-30 14:51:16,136 - INFO - [0000] 248/1250: 0.722335333\n",
      "2025-09-30 14:51:26,386 - INFO - [0000] 310/1250: 0.734688895\n",
      "2025-09-30 14:51:36,157 - INFO - [0000] 372/1250: 0.999006193\n",
      "2025-09-30 14:51:45,928 - INFO - [0000] 434/1250: 0.820556475\n",
      "2025-09-30 14:51:54,365 - INFO - [0000] 496/1250: 0.827215005\n",
      "2025-09-30 14:52:04,677 - INFO - [0000] 558/1250: 0.499983993\n",
      "2025-09-30 14:52:15,395 - INFO - [0000] 620/1250: 0.902443884\n",
      "2025-09-30 14:52:25,418 - INFO - [0000] 682/1250: 0.791729529\n",
      "2025-09-30 14:52:34,037 - INFO - [0000] 744/1250: 0.670759573\n",
      "2025-09-30 14:52:45,633 - INFO - [0000] 806/1250: 0.685636595\n",
      "2025-09-30 14:52:56,885 - INFO - [0000] 868/1250: 0.897269911\n",
      "2025-09-30 14:53:07,423 - INFO - [0000] 930/1250: 0.884171157\n",
      "2025-09-30 14:53:17,216 - INFO - [0000] 992/1250: 1.038045575\n",
      "2025-09-30 14:53:28,626 - INFO - [0000] 1054/1250: 0.738699773\n",
      "2025-09-30 14:53:37,275 - INFO - [0000] 1116/1250: 0.910792253\n",
      "2025-09-30 14:53:47,029 - INFO - [0000] 1178/1250: 0.791044677\n",
      "2025-09-30 14:53:57,038 - INFO - [0000] 1240/1250: 0.985993998\n",
      "2025-09-30 14:54:07,046 - INFO - [0000]: 0.806882546 - train acc: 51.7 - valid_acc: 51.6\n",
      "2025-09-30 14:55:07,046 - INFO - [0001] 0/1250: 0.837701722\n",
      "2025-09-30 14:55:15,704 - INFO - [0001] 62/1250: 0.492791735\n",
      "2025-09-30 14:55:24,930 - INFO - [0001] 124/1250: 0.95342647\n",
      "2025-09-30 14:55:33,841 - INFO - [0001] 186/1250: 0.654412609\n",
      "2025-09-30 14:55:44,733 - INFO - [0001] 248/1250: 0.726364561\n",
      "2025-09-30 14:55:54,734 - INFO - [0001] 310/1250: 0.997851875\n",
      "2025-09-30 14:56:05,668 - INFO - [0001] 372/1250: 0.618710979\n",
      "2025-09-30 14:56:16,791 - INFO - [0001] 434/1250: 0.710394642\n",
      "2025-09-30 14:56:28,153 - INFO - [0001] 496/1250: 0.724747991\n",
      "2025-09-30 14:56:39,325 - INFO - [0001] 558/1250: 0.680792295\n",
      "2025-09-30 14:56:51,023 - INFO - [0001] 620/1250: 0.939264849\n",
      "2025-09-30 14:57:00,188 - INFO - [0001] 682/1250: 0.72690106\n",
      "2025-09-30 14:57:10,142 - INFO - [0001] 744/1250: 0.900016708\n",
      "2025-09-30 14:57:20,136 - INFO - [0001] 806/1250: 1.024864218\n",
      "2025-09-30 14:57:29,608 - INFO - [0001] 868/1250: 0.580067404\n",
      "2025-09-30 14:57:40,692 - INFO - [0001] 930/1250: 0.98731222\n",
      "2025-09-30 14:57:49,174 - INFO - [0001] 992/1250: 0.488822335\n",
      "2025-09-30 14:57:59,181 - INFO - [0001] 1054/1250: 0.95247333\n",
      "2025-09-30 14:58:09,388 - INFO - [0001] 1116/1250: 0.627727166\n",
      "2025-09-30 14:58:18,498 - INFO - [0001] 1178/1250: 1.035263606\n",
      "2025-09-30 14:58:29,614 - INFO - [0001] 1240/1250: 0.75124836\n",
      "2025-09-30 14:58:37,960 - INFO - [0001]: 0.684038534 - train acc: 53.1431 - valid_acc: 53.0112\n",
      "2025-09-30 14:59:37,960 - INFO - [0002] 0/1250: 0.577747156\n",
      "2025-09-30 14:59:47,990 - INFO - [0002] 62/1250: 0.734219493\n",
      "2025-09-30 14:59:59,798 - INFO - [0002] 124/1250: 0.621435722\n",
      "2025-09-30 15:00:08,146 - INFO - [0002] 186/1250: 0.668821139\n",
      "2025-09-30 15:00:18,006 - INFO - [0002] 248/1250: 1.047590627\n",
      "2025-09-30 15:00:28,780 - INFO - [0002] 310/1250: 0.68793487\n",
      "2025-09-30 15:00:38,669 - INFO - [0002] 372/1250: 0.69515585\n",
      "2025-09-30 15:00:47,909 - INFO - [0002] 434/1250: 1.017218518\n",
      "2025-09-30 15:00:56,548 - INFO - [0002] 496/1250: 0.677334434\n",
      "2025-09-30 15:01:05,281 - INFO - [0002] 558/1250: 0.943921399\n",
      "2025-09-30 15:01:14,808 - INFO - [0002] 620/1250: 0.946876598\n",
      "2025-09-30 15:01:22,937 - INFO - [0002] 682/1250: 0.935989864\n",
      "2025-09-30 15:01:33,076 - INFO - [0002] 744/1250: 1.026069714\n",
      "2025-09-30 15:01:43,632 - INFO - [0002] 806/1250: 0.752587938\n",
      "2025-09-30 15:01:55,267 - INFO - [0002] 868/1250: 0.586587116\n",
      "2025-09-30 15:02:05,040 - INFO - [0002] 930/1250: 0.772857148\n",
      "2025-09-30 15:02:14,114 - INFO - [0002] 992/1250: 0.983782266\n",
      "2025-09-30 15:02:23,974 - INFO - [0002] 1054/1250: 0.67258445\n",
      "2025-09-30 15:02:35,761 - INFO - [0002] 1116/1250: 1.008289373\n",
      "2025-09-30 15:02:45,412 - INFO - [0002] 1178/1250: 0.936447119\n",
      "2025-09-30 15:02:56,119 - INFO - [0002] 1240/1250: 1.042380783\n",
      "2025-09-30 15:03:07,736 - INFO - [0002]: 0.71878001 - train acc: 54.5862 - valid_acc: 54.4223\n",
      "2025-09-30 15:04:07,736 - INFO - [0003] 0/1250: 0.464847968\n",
      "2025-09-30 15:04:18,492 - INFO - [0003] 62/1250: 0.521653841\n",
      "2025-09-30 15:04:28,457 - INFO - [0003] 124/1250: 0.452398249\n",
      "2025-09-30 15:04:36,888 - INFO - [0003] 186/1250: 0.519697424\n",
      "2025-09-30 15:04:47,826 - INFO - [0003] 248/1250: 1.012366362\n",
      "2025-09-30 15:04:57,696 - INFO - [0003] 310/1250: 0.879472694\n",
      "2025-09-30 15:05:09,317 - INFO - [0003] 372/1250: 0.999602083\n",
      "2025-09-30 15:05:21,213 - INFO - [0003] 434/1250: 0.701969227\n",
      "2025-09-30 15:05:29,758 - INFO - [0003] 496/1250: 0.874412902\n",
      "2025-09-30 15:05:40,751 - INFO - [0003] 558/1250: 0.450507798\n",
      "2025-09-30 15:05:49,711 - INFO - [0003] 620/1250: 1.044908761\n",
      "2025-09-30 15:06:00,008 - INFO - [0003] 682/1250: 0.574565385\n",
      "2025-09-30 15:06:10,148 - INFO - [0003] 744/1250: 0.775968005\n",
      "2025-09-30 15:06:21,136 - INFO - [0003] 806/1250: 0.873622963\n",
      "2025-09-30 15:06:31,400 - INFO - [0003] 868/1250: 0.753802741\n",
      "2025-09-30 15:06:41,671 - INFO - [0003] 930/1250: 0.734751786\n",
      "2025-09-30 15:06:50,416 - INFO - [0003] 992/1250: 0.555467412\n",
      "2025-09-30 15:07:01,705 - INFO - [0003] 1054/1250: 0.784054617\n",
      "2025-09-30 15:07:12,241 - INFO - [0003] 1116/1250: 0.583940085\n",
      "2025-09-30 15:07:20,489 - INFO - [0003] 1178/1250: 0.9550719\n",
      "2025-09-30 15:07:29,982 - INFO - [0003] 1240/1250: 1.000485625\n",
      "2025-09-30 15:07:39,063 - INFO - [0003]: 0.807514308 - train acc: 56.0293 - valid_acc: 55.8335\n",
      "2025-09-30 15:08:39,063 - INFO - [0004] 0/1250: 0.8972675\n",
      "2025-09-30 15:08:49,439 - INFO - [0004] 62/1250: 0.540203997\n",
      "2025-09-30 15:08:57,849 - INFO - [0004] 124/1250: 0.739423459\n",
      "2025-09-30 15:09:06,614 - INFO - [0004] 186/1250: 0.802570579\n",
      "2025-09-30 15:09:14,820 - INFO - [0004] 248/1250: 0.804921567\n",
      "2025-09-30 15:09:26,587 - INFO - [0004] 310/1250: 0.61246609\n",
      "2025-09-30 15:09:35,543 - INFO - [0004] 372/1250: 1.024907628\n",
      "2025-09-30 15:09:44,372 - INFO - [0004] 434/1250: 0.925976157\n",
      "2025-09-30 15:09:54,321 - INFO - [0004] 496/1250: 0.829685703\n",
      "2025-09-30 15:10:02,809 - INFO - [0004] 558/1250: 0.807498928\n",
      "2025-09-30 15:10:11,257 - INFO - [0004] 620/1250: 0.619532623\n",
      "2025-09-30 15:10:23,220 - INFO - [0004] 682/1250: 0.482873134\n",
      "2025-09-30 15:10:32,959 - INFO - [0004] 744/1250: 0.776544437\n",
      "2025-09-30 15:10:44,279 - INFO - [0004] 806/1250: 0.894514825\n",
      "2025-09-30 15:10:55,228 - INFO - [0004] 868/1250: 0.586583985\n",
      "2025-09-30 15:11:04,030 - INFO - [0004] 930/1250: 0.485542724\n",
      "2025-09-30 15:11:12,617 - INFO - [0004] 992/1250: 0.772461435\n",
      "2025-09-30 15:11:21,760 - INFO - [0004] 1054/1250: 0.960267639\n",
      "2025-09-30 15:11:33,454 - INFO - [0004] 1116/1250: 0.609609422\n",
      "2025-09-30 15:11:45,161 - INFO - [0004] 1178/1250: 0.880961565\n",
      "2025-09-30 15:11:53,162 - INFO - [0004] 1240/1250: 1.041666959\n",
      "2025-09-30 15:12:01,855 - INFO - [0004]: 0.803707551 - train acc: 57.4724 - valid_acc: 57.2446\n",
      "2025-09-30 15:13:01,855 - INFO - [0005] 0/1250: 0.575895364\n",
      "2025-09-30 15:13:12,233 - INFO - [0005] 62/1250: 0.480776143\n",
      "2025-09-30 15:13:23,753 - INFO - [0005] 124/1250: 0.771232069\n",
      "2025-09-30 15:13:33,913 - INFO - [0005] 186/1250: 0.458968439\n",
      "2025-09-30 15:13:44,125 - INFO - [0005] 248/1250: 0.914952563\n",
      "2025-09-30 15:13:54,495 - INFO - [0005] 310/1250: 0.592919862\n",
      "2025-09-30 15:14:05,528 - INFO - [0005] 372/1250: 0.500399809\n",
      "2025-09-30 15:14:17,101 - INFO - [0005] 434/1250: 0.868857836\n",
      "2025-09-30 15:14:28,889 - INFO - [0005] 496/1250: 1.043987762\n",
      "2025-09-30 15:14:39,419 - INFO - [0005] 558/1250: 0.640550003\n",
      "2025-09-30 15:14:49,220 - INFO - [0005] 620/1250: 0.798739719\n",
      "2025-09-30 15:15:00,578 - INFO - [0005] 682/1250: 0.78431654\n",
      "2025-09-30 15:15:09,175 - INFO - [0005] 744/1250: 1.037235655\n",
      "2025-09-30 15:15:20,147 - INFO - [0005] 806/1250: 0.719365894\n",
      "2025-09-30 15:15:30,434 - INFO - [0005] 868/1250: 0.50548709\n",
      "2025-09-30 15:15:40,268 - INFO - [0005] 930/1250: 0.642574934\n",
      "2025-09-30 15:15:50,255 - INFO - [0005] 992/1250: 0.75113436\n",
      "2025-09-30 15:15:59,283 - INFO - [0005] 1054/1250: 0.997681894\n",
      "2025-09-30 15:16:08,783 - INFO - [0005] 1116/1250: 0.928701675\n",
      "2025-09-30 15:16:17,587 - INFO - [0005] 1178/1250: 0.695970068\n",
      "2025-09-30 15:16:26,765 - INFO - [0005] 1240/1250: 1.000809867\n",
      "2025-09-30 15:16:36,840 - INFO - [0005]: 0.689646386 - train acc: 58.9156 - valid_acc: 58.6558\n",
      "2025-09-30 15:17:36,840 - INFO - [0006] 0/1250: 0.472247876\n",
      "2025-09-30 15:17:46,682 - INFO - [0006] 62/1250: 1.026123903\n",
      "2025-09-30 15:17:57,446 - INFO - [0006] 124/1250: 0.655734912\n",
      "2025-09-30 15:18:08,933 - INFO - [0006] 186/1250: 0.494971893\n",
      "2025-09-30 15:18:19,296 - INFO - [0006] 248/1250: 0.515786278\n",
      "2025-09-30 15:18:29,055 - INFO - [0006] 310/1250: 0.487971082\n",
      "2025-09-30 15:18:40,204 - INFO - [0006] 372/1250: 0.557298659\n",
      "2025-09-30 15:18:51,823 - INFO - [0006] 434/1250: 0.513087526\n",
      "2025-09-30 15:19:02,952 - INFO - [0006] 496/1250: 0.989613107\n",
      "2025-09-30 15:19:12,546 - INFO - [0006] 558/1250: 0.510295328\n",
      "2025-09-30 15:19:22,263 - INFO - [0006] 620/1250: 0.804758201\n",
      "2025-09-30 15:19:32,166 - INFO - [0006] 682/1250: 0.587740388\n",
      "2025-09-30 15:19:43,322 - INFO - [0006] 744/1250: 0.755181452\n",
      "2025-09-30 15:19:53,658 - INFO - [0006] 806/1250: 0.551453049\n",
      "2025-09-30 15:20:04,464 - INFO - [0006] 868/1250: 0.796338412\n",
      "2025-09-30 15:20:15,520 - INFO - [0006] 930/1250: 1.010391011\n",
      "2025-09-30 15:20:27,486 - INFO - [0006] 992/1250: 0.596094033\n",
      "2025-09-30 15:20:39,312 - INFO - [0006] 1054/1250: 0.951511939\n",
      "2025-09-30 15:20:48,244 - INFO - [0006] 1116/1250: 0.619940574\n",
      "2025-09-30 15:20:58,061 - INFO - [0006] 1178/1250: 0.765831901\n",
      "2025-09-30 15:21:09,837 - INFO - [0006] 1240/1250: 0.99174818\n",
      "2025-09-30 15:21:18,933 - INFO - [0006]: 0.664123841 - train acc: 60.3587 - valid_acc: 60.0669\n",
      "2025-09-30 15:22:18,933 - INFO - [0007] 0/1250: 0.749127536\n",
      "2025-09-30 15:22:30,483 - INFO - [0007] 62/1250: 0.648190516\n",
      "2025-09-30 15:22:39,925 - INFO - [0007] 124/1250: 0.996395886\n",
      "2025-09-30 15:22:49,675 - INFO - [0007] 186/1250: 0.902324512\n",
      "2025-09-30 15:23:01,562 - INFO - [0007] 248/1250: 0.920791919\n",
      "2025-09-30 15:23:11,019 - INFO - [0007] 310/1250: 0.591105724\n",
      "2025-09-30 15:23:20,930 - INFO - [0007] 372/1250: 0.778533011\n",
      "2025-09-30 15:23:32,285 - INFO - [0007] 434/1250: 0.485298456\n",
      "2025-09-30 15:23:41,938 - INFO - [0007] 496/1250: 0.949587021\n",
      "2025-09-30 15:23:52,093 - INFO - [0007] 558/1250: 0.836157483\n",
      "2025-09-30 15:24:01,403 - INFO - [0007] 620/1250: 0.987827476\n",
      "2025-09-30 15:24:10,825 - INFO - [0007] 682/1250: 0.643360831\n",
      "2025-09-30 15:24:19,873 - INFO - [0007] 744/1250: 0.785986988\n",
      "2025-09-30 15:24:28,955 - INFO - [0007] 806/1250: 0.528850304\n",
      "2025-09-30 15:24:39,006 - INFO - [0007] 868/1250: 0.516746895\n",
      "2025-09-30 15:24:47,659 - INFO - [0007] 930/1250: 0.885001335\n",
      "2025-09-30 15:24:58,840 - INFO - [0007] 992/1250: 0.982631311\n",
      "2025-09-30 15:25:10,194 - INFO - [0007] 1054/1250: 0.853577521\n",
      "2025-09-30 15:25:21,855 - INFO - [0007] 1116/1250: 0.820643526\n",
      "2025-09-30 15:25:31,003 - INFO - [0007] 1178/1250: 0.454806161\n",
      "2025-09-30 15:25:42,239 - INFO - [0007] 1240/1250: 0.694456577\n",
      "2025-09-30 15:25:51,756 - INFO - [0007]: 0.796280502 - train acc: 61.8018 - valid_acc: 61.4781\n",
      "2025-09-30 15:26:51,756 - INFO - [0008] 0/1250: 0.846241372\n",
      "2025-09-30 15:27:01,330 - INFO - [0008] 62/1250: 0.466895943\n",
      "2025-09-30 15:27:12,156 - INFO - [0008] 124/1250: 0.960549699\n",
      "2025-09-30 15:27:20,715 - INFO - [0008] 186/1250: 0.458906242\n",
      "2025-09-30 15:27:32,623 - INFO - [0008] 248/1250: 0.638683384\n",
      "2025-09-30 15:27:40,654 - INFO - [0008] 310/1250: 0.576965776\n",
      "2025-09-30 15:27:52,540 - INFO - [0008] 372/1250: 0.59589684\n",
      "2025-09-30 15:28:02,437 - INFO - [0008] 434/1250: 0.677332831\n",
      "2025-09-30 15:28:11,810 - INFO - [0008] 496/1250: 0.782990795\n",
      "2025-09-30 15:28:22,694 - INFO - [0008] 558/1250: 0.889278349\n",
      "2025-09-30 15:28:33,109 - INFO - [0008] 620/1250: 0.850372323\n",
      "2025-09-30 15:28:42,283 - INFO - [0008] 682/1250: 0.831384983\n",
      "2025-09-30 15:28:53,711 - INFO - [0008] 744/1250: 1.028192381\n",
      "2025-09-30 15:29:04,521 - INFO - [0008] 806/1250: 0.937235748\n",
      "2025-09-30 15:29:13,875 - INFO - [0008] 868/1250: 0.553385371\n",
      "2025-09-30 15:29:24,625 - INFO - [0008] 930/1250: 0.996479139\n",
      "2025-09-30 15:29:32,700 - INFO - [0008] 992/1250: 0.748199979\n",
      "2025-09-30 15:29:42,673 - INFO - [0008] 1054/1250: 0.737760237\n",
      "2025-09-30 15:29:51,306 - INFO - [0008] 1116/1250: 0.594415862\n",
      "2025-09-30 15:30:01,117 - INFO - [0008] 1178/1250: 0.570344408\n",
      "2025-09-30 15:30:10,704 - INFO - [0008] 1240/1250: 0.764073644\n",
      "2025-09-30 15:30:20,388 - INFO - [0008]: 0.680012161 - train acc: 63.2449 - valid_acc: 62.8892\n",
      "2025-09-30 15:31:20,388 - INFO - [0009] 0/1250: 0.719830621\n",
      "2025-09-30 15:31:29,900 - INFO - [0009] 62/1250: 0.808389789\n",
      "2025-09-30 15:31:39,737 - INFO - [0009] 124/1250: 0.480228669\n",
      "2025-09-30 15:31:48,829 - INFO - [0009] 186/1250: 0.890106874\n",
      "2025-09-30 15:31:58,913 - INFO - [0009] 248/1250: 0.667076465\n",
      "2025-09-30 15:32:10,008 - INFO - [0009] 310/1250: 1.001027401\n",
      "2025-09-30 15:32:18,985 - INFO - [0009] 372/1250: 0.886248165\n",
      "2025-09-30 15:32:30,649 - INFO - [0009] 434/1250: 0.76108168\n",
      "2025-09-30 15:32:41,534 - INFO - [0009] 496/1250: 0.518291519\n",
      "2025-09-30 15:32:51,759 - INFO - [0009] 558/1250: 0.784605333\n",
      "2025-09-30 15:33:02,577 - INFO - [0009] 620/1250: 0.668045387\n",
      "2025-09-30 15:33:11,718 - INFO - [0009] 682/1250: 0.825952948\n",
      "2025-09-30 15:33:20,927 - INFO - [0009] 744/1250: 0.696429667\n",
      "2025-09-30 15:33:29,610 - INFO - [0009] 806/1250: 0.993270751\n",
      "2025-09-30 15:33:38,084 - INFO - [0009] 868/1250: 0.630285245\n",
      "2025-09-30 15:33:49,956 - INFO - [0009] 930/1250: 0.992639922\n",
      "2025-09-30 15:34:01,347 - INFO - [0009] 992/1250: 0.863298797\n",
      "2025-09-30 15:34:09,609 - INFO - [0009] 1054/1250: 0.558250164\n",
      "2025-09-30 15:34:19,236 - INFO - [0009] 1116/1250: 0.558494397\n",
      "2025-09-30 15:34:28,735 - INFO - [0009] 1178/1250: 0.63582526\n",
      "2025-09-30 15:34:40,672 - INFO - [0009] 1240/1250: 0.539597984\n",
      "2025-09-30 15:34:50,160 - INFO - [0009]: 0.843091085 - train acc: 64.688 - valid_acc: 64.3004\n",
      "2025-09-30 15:35:50,160 - INFO - [0010] 0/1250: 0.71503889\n",
      "2025-09-30 15:36:02,065 - INFO - [0010] 62/1250: 0.452083104\n",
      "2025-09-30 15:36:11,767 - INFO - [0010] 124/1250: 0.49506636\n",
      "2025-09-30 15:36:21,333 - INFO - [0010] 186/1250: 0.467932359\n",
      "2025-09-30 15:36:29,472 - INFO - [0010] 248/1250: 0.667627127\n",
      "2025-09-30 15:36:38,597 - INFO - [0010] 310/1250: 0.489283539\n",
      "2025-09-30 15:36:49,430 - INFO - [0010] 372/1250: 0.928940015\n",
      "2025-09-30 15:37:00,552 - INFO - [0010] 434/1250: 0.696061966\n",
      "2025-09-30 15:37:09,142 - INFO - [0010] 496/1250: 0.595763016\n",
      "2025-09-30 15:37:21,046 - INFO - [0010] 558/1250: 0.602267724\n",
      "2025-09-30 15:37:29,685 - INFO - [0010] 620/1250: 0.629177999\n",
      "2025-09-30 15:37:39,556 - INFO - [0010] 682/1250: 1.032288764\n",
      "2025-09-30 15:37:51,052 - INFO - [0010] 744/1250: 0.847850242\n",
      "2025-09-30 15:37:59,948 - INFO - [0010] 806/1250: 0.584711325\n",
      "2025-09-30 15:38:10,867 - INFO - [0010] 868/1250: 1.043603045\n",
      "2025-09-30 15:38:20,969 - INFO - [0010] 930/1250: 0.600954348\n",
      "2025-09-30 15:38:30,838 - INFO - [0010] 992/1250: 0.626464933\n",
      "2025-09-30 15:38:39,443 - INFO - [0010] 1054/1250: 0.660350091\n",
      "2025-09-30 15:38:51,127 - INFO - [0010] 1116/1250: 0.687727035\n",
      "2025-09-30 15:38:59,858 - INFO - [0010] 1178/1250: 0.497840212\n",
      "2025-09-30 15:39:09,605 - INFO - [0010] 1240/1250: 0.979448806\n",
      "2025-09-30 15:39:17,671 - INFO - [0010]: 0.74093607 - train acc: 66.1311 - valid_acc: 65.7116\n",
      "2025-09-30 15:40:17,671 - INFO - [0011] 0/1250: 0.646112414\n",
      "2025-09-30 15:40:26,325 - INFO - [0011] 62/1250: 0.675891107\n",
      "2025-09-30 15:40:35,620 - INFO - [0011] 124/1250: 0.80121529\n",
      "2025-09-30 15:40:46,317 - INFO - [0011] 186/1250: 1.006408636\n",
      "2025-09-30 15:40:58,269 - INFO - [0011] 248/1250: 0.807704178\n",
      "2025-09-30 15:41:09,163 - INFO - [0011] 310/1250: 0.694375214\n",
      "2025-09-30 15:41:17,255 - INFO - [0011] 372/1250: 0.77710697\n",
      "2025-09-30 15:41:28,038 - INFO - [0011] 434/1250: 0.51209633\n",
      "2025-09-30 15:41:38,020 - INFO - [0011] 496/1250: 0.955161009\n",
      "2025-09-30 15:41:46,119 - INFO - [0011] 558/1250: 0.782145659\n",
      "2025-09-30 15:41:56,833 - INFO - [0011] 620/1250: 1.00868823\n",
      "2025-09-30 15:42:05,044 - INFO - [0011] 682/1250: 0.968218219\n",
      "2025-09-30 15:42:13,096 - INFO - [0011] 744/1250: 0.610047783\n",
      "2025-09-30 15:42:23,272 - INFO - [0011] 806/1250: 0.516779626\n",
      "2025-09-30 15:42:32,514 - INFO - [0011] 868/1250: 0.618221853\n",
      "2025-09-30 15:42:44,423 - INFO - [0011] 930/1250: 0.816858919\n",
      "2025-09-30 15:42:54,721 - INFO - [0011] 992/1250: 0.504193333\n",
      "2025-09-30 15:43:05,710 - INFO - [0011] 1054/1250: 0.744301134\n",
      "2025-09-30 15:43:14,922 - INFO - [0011] 1116/1250: 0.826194009\n",
      "2025-09-30 15:43:25,313 - INFO - [0011] 1178/1250: 0.937728038\n",
      "2025-09-30 15:43:33,655 - INFO - [0011] 1240/1250: 0.561990447\n",
      "2025-09-30 15:43:42,571 - INFO - [0011]: 0.672594277 - train acc: 67.5742 - valid_acc: 67.1227\n",
      "2025-09-30 15:44:42,571 - INFO - [0012] 0/1250: 1.020958957\n",
      "2025-09-30 15:44:53,474 - INFO - [0012] 62/1250: 0.879678469\n",
      "2025-09-30 15:45:05,185 - INFO - [0012] 124/1250: 0.848355383\n",
      "2025-09-30 15:45:16,573 - INFO - [0012] 186/1250: 0.476566551\n",
      "2025-09-30 15:45:28,447 - INFO - [0012] 248/1250: 0.865311905\n",
      "2025-09-30 15:45:39,451 - INFO - [0012] 310/1250: 1.011264706\n",
      "2025-09-30 15:45:48,868 - INFO - [0012] 372/1250: 0.461481087\n",
      "2025-09-30 15:45:57,631 - INFO - [0012] 434/1250: 0.93685025\n",
      "2025-09-30 15:46:07,414 - INFO - [0012] 496/1250: 0.670351511\n",
      "2025-09-30 15:46:18,774 - INFO - [0012] 558/1250: 0.86881285\n",
      "2025-09-30 15:46:30,344 - INFO - [0012] 620/1250: 0.887229322\n",
      "2025-09-30 15:46:39,518 - INFO - [0012] 682/1250: 0.557083404\n",
      "2025-09-30 15:46:50,792 - INFO - [0012] 744/1250: 0.480947695\n",
      "2025-09-30 15:47:02,342 - INFO - [0012] 806/1250: 0.54031611\n",
      "2025-09-30 15:47:14,192 - INFO - [0012] 868/1250: 0.706409329\n",
      "2025-09-30 15:47:22,979 - INFO - [0012] 930/1250: 0.454162955\n",
      "2025-09-30 15:47:32,199 - INFO - [0012] 992/1250: 0.864010798\n",
      "2025-09-30 15:47:41,565 - INFO - [0012] 1054/1250: 0.7770923\n",
      "2025-09-30 15:47:52,747 - INFO - [0012] 1116/1250: 1.032325236\n",
      "2025-09-30 15:48:02,227 - INFO - [0012] 1178/1250: 0.529559934\n",
      "2025-09-30 15:48:13,183 - INFO - [0012] 1240/1250: 0.613400313\n",
      "2025-09-30 15:48:21,734 - INFO - [0012]: 0.655083133 - train acc: 69.0173 - valid_acc: 68.5339\n",
      "2025-09-30 15:49:21,734 - INFO - [0013] 0/1250: 0.787369051\n",
      "2025-09-30 15:49:32,398 - INFO - [0013] 62/1250: 0.514683426\n",
      "2025-09-30 15:49:40,674 - INFO - [0013] 124/1250: 0.943928418\n",
      "2025-09-30 15:49:50,668 - INFO - [0013] 186/1250: 0.661810034\n",
      "2025-09-30 15:50:02,324 - INFO - [0013] 248/1250: 0.848964431\n",
      "2025-09-30 15:50:11,719 - INFO - [0013] 310/1250: 0.761366815\n",
      "2025-09-30 15:50:21,097 - INFO - [0013] 372/1250: 1.038559628\n",
      "2025-09-30 15:50:30,108 - INFO - [0013] 434/1250: 0.983613731\n",
      "2025-09-30 15:50:41,252 - INFO - [0013] 496/1250: 0.795310825\n",
      "2025-09-30 15:50:51,223 - INFO - [0013] 558/1250: 1.047128825\n",
      "2025-09-30 15:51:00,715 - INFO - [0013] 620/1250: 0.946829569\n",
      "2025-09-30 15:51:09,975 - INFO - [0013] 682/1250: 0.801713675\n",
      "2025-09-30 15:51:19,767 - INFO - [0013] 744/1250: 0.95617117\n",
      "2025-09-30 15:51:29,738 - INFO - [0013] 806/1250: 0.905687081\n",
      "2025-09-30 15:51:40,177 - INFO - [0013] 868/1250: 0.508577334\n",
      "2025-09-30 15:51:49,812 - INFO - [0013] 930/1250: 0.649088817\n",
      "2025-09-30 15:51:58,781 - INFO - [0013] 992/1250: 0.986562741\n",
      "2025-09-30 15:52:09,287 - INFO - [0013] 1054/1250: 0.990338237\n",
      "2025-09-30 15:52:20,494 - INFO - [0013] 1116/1250: 0.482536295\n",
      "2025-09-30 15:52:32,380 - INFO - [0013] 1178/1250: 0.559772438\n",
      "2025-09-30 15:52:43,858 - INFO - [0013] 1240/1250: 0.824766568\n",
      "2025-09-30 15:52:54,424 - INFO - [0013]: 0.736552781 - train acc: 70.4605 - valid_acc: 69.945\n",
      "2025-09-30 15:53:54,424 - INFO - [0014] 0/1250: 1.027771379\n",
      "2025-09-30 15:54:05,215 - INFO - [0014] 62/1250: 1.010877629\n",
      "2025-09-30 15:54:15,755 - INFO - [0014] 124/1250: 0.818208814\n",
      "2025-09-30 15:54:24,361 - INFO - [0014] 186/1250: 0.822655454\n",
      "2025-09-30 15:54:32,713 - INFO - [0014] 248/1250: 0.927035347\n",
      "2025-09-30 15:54:42,648 - INFO - [0014] 310/1250: 1.044192257\n",
      "2025-09-30 15:54:50,698 - INFO - [0014] 372/1250: 0.831515946\n",
      "2025-09-30 15:55:01,465 - INFO - [0014] 434/1250: 0.473924263\n",
      "2025-09-30 15:55:13,247 - INFO - [0014] 496/1250: 1.001317589\n",
      "2025-09-30 15:55:24,121 - INFO - [0014] 558/1250: 0.951381814\n",
      "2025-09-30 15:55:34,822 - INFO - [0014] 620/1250: 1.044834436\n",
      "2025-09-30 15:55:44,967 - INFO - [0014] 682/1250: 0.470870853\n",
      "2025-09-30 15:55:55,064 - INFO - [0014] 744/1250: 0.76433987\n",
      "2025-09-30 15:56:04,750 - INFO - [0014] 806/1250: 0.756701121\n",
      "2025-09-30 15:56:13,721 - INFO - [0014] 868/1250: 0.965772468\n",
      "2025-09-30 15:56:23,758 - INFO - [0014] 930/1250: 0.907541014\n",
      "2025-09-30 15:56:32,005 - INFO - [0014] 992/1250: 1.006040579\n",
      "2025-09-30 15:56:40,013 - INFO - [0014] 1054/1250: 0.586593222\n",
      "2025-09-30 15:56:49,947 - INFO - [0014] 1116/1250: 0.923846695\n",
      "2025-09-30 15:57:00,156 - INFO - [0014] 1178/1250: 0.978289317\n",
      "2025-09-30 15:57:09,855 - INFO - [0014] 1240/1250: 0.646419361\n",
      "2025-09-30 15:57:19,597 - INFO - [0014]: 0.804724006 - train acc: 71.9036 - valid_acc: 71.3562\n",
      "2025-09-30 15:58:19,597 - INFO - [0015] 0/1250: 0.789429663\n",
      "2025-09-30 15:58:29,261 - INFO - [0015] 62/1250: 0.735522363\n",
      "2025-09-30 15:58:37,808 - INFO - [0015] 124/1250: 0.481956606\n",
      "2025-09-30 15:58:49,217 - INFO - [0015] 186/1250: 0.846078416\n",
      "2025-09-30 15:58:58,642 - INFO - [0015] 248/1250: 0.668903745\n",
      "2025-09-30 15:59:10,130 - INFO - [0015] 310/1250: 0.565385568\n",
      "2025-09-30 15:59:18,474 - INFO - [0015] 372/1250: 0.975646033\n",
      "2025-09-30 15:59:30,454 - INFO - [0015] 434/1250: 0.652791003\n",
      "2025-09-30 15:59:40,177 - INFO - [0015] 496/1250: 0.692843237\n",
      "2025-09-30 15:59:50,242 - INFO - [0015] 558/1250: 0.619429845\n",
      "2025-09-30 15:59:59,136 - INFO - [0015] 620/1250: 0.716942005\n",
      "2025-09-30 16:00:09,044 - INFO - [0015] 682/1250: 0.539251463\n",
      "2025-09-30 16:00:18,439 - INFO - [0015] 744/1250: 0.468912425\n",
      "2025-09-30 16:00:30,055 - INFO - [0015] 806/1250: 0.678673216\n",
      "2025-09-30 16:00:40,513 - INFO - [0015] 868/1250: 0.579657553\n",
      "2025-09-30 16:00:49,134 - INFO - [0015] 930/1250: 0.506981854\n",
      "2025-09-30 16:01:00,536 - INFO - [0015] 992/1250: 0.654073872\n",
      "2025-09-30 16:01:08,928 - INFO - [0015] 1054/1250: 0.608867644\n",
      "2025-09-30 16:01:19,460 - INFO - [0015] 1116/1250: 0.578940268\n",
      "2025-09-30 16:01:29,294 - INFO - [0015] 1178/1250: 0.726874184\n",
      "2025-09-30 16:01:39,562 - INFO - [0015] 1240/1250: 0.767334576\n",
      "2025-09-30 16:01:49,420 - INFO - [0015]: 0.770885764 - train acc: 73.3467 - valid_acc: 72.7673\n",
      "2025-09-30 16:02:49,420 - INFO - [0016] 0/1250: 0.575200339\n",
      "2025-09-30 16:02:57,790 - INFO - [0016] 62/1250: 0.805867253\n",
      "2025-09-30 16:03:08,788 - INFO - [0016] 124/1250: 0.876637207\n",
      "2025-09-30 16:03:18,804 - INFO - [0016] 186/1250: 0.452198673\n",
      "2025-09-30 16:03:28,323 - INFO - [0016] 248/1250: 0.94380575\n",
      "2025-09-30 16:03:36,986 - INFO - [0016] 310/1250: 0.692542228\n",
      "2025-09-30 16:03:48,520 - INFO - [0016] 372/1250: 0.899893528\n",
      "2025-09-30 16:03:57,765 - INFO - [0016] 434/1250: 1.028679749\n",
      "2025-09-30 16:04:08,004 - INFO - [0016] 496/1250: 0.723415364\n",
      "2025-09-30 16:04:18,154 - INFO - [0016] 558/1250: 0.501512768\n",
      "2025-09-30 16:04:28,163 - INFO - [0016] 620/1250: 0.770228488\n",
      "2025-09-30 16:04:39,012 - INFO - [0016] 682/1250: 0.825217508\n",
      "2025-09-30 16:04:48,109 - INFO - [0016] 744/1250: 0.515041695\n",
      "2025-09-30 16:04:59,693 - INFO - [0016] 806/1250: 0.615924137\n",
      "2025-09-30 16:05:11,674 - INFO - [0016] 868/1250: 0.961955288\n",
      "2025-09-30 16:05:22,185 - INFO - [0016] 930/1250: 0.914846388\n",
      "2025-09-30 16:05:30,857 - INFO - [0016] 992/1250: 0.980505209\n",
      "2025-09-30 16:05:40,183 - INFO - [0016] 1054/1250: 1.009777373\n",
      "2025-09-30 16:05:50,584 - INFO - [0016] 1116/1250: 1.038964536\n",
      "2025-09-30 16:06:01,515 - INFO - [0016] 1178/1250: 1.027940479\n",
      "2025-09-30 16:06:10,794 - INFO - [0016] 1240/1250: 0.618395521\n",
      "2025-09-30 16:06:22,591 - INFO - [0016]: 0.761733075 - train acc: 74.7898 - valid_acc: 74.1785\n",
      "2025-09-30 16:07:22,591 - INFO - [0017] 0/1250: 0.552031299\n",
      "2025-09-30 16:07:33,484 - INFO - [0017] 62/1250: 0.532191813\n",
      "2025-09-30 16:07:45,317 - INFO - [0017] 124/1250: 1.033966363\n",
      "2025-09-30 16:07:55,336 - INFO - [0017] 186/1250: 0.777121096\n",
      "2025-09-30 16:08:03,369 - INFO - [0017] 248/1250: 0.979221952\n",
      "2025-09-30 16:08:14,790 - INFO - [0017] 310/1250: 0.962071999\n",
      "2025-09-30 16:08:24,626 - INFO - [0017] 372/1250: 0.667711011\n",
      "2025-09-30 16:08:34,753 - INFO - [0017] 434/1250: 1.030683241\n",
      "2025-09-30 16:08:46,582 - INFO - [0017] 496/1250: 0.994566563\n",
      "2025-09-30 16:08:57,395 - INFO - [0017] 558/1250: 0.844678041\n",
      "2025-09-30 16:09:08,125 - INFO - [0017] 620/1250: 0.681410039\n",
      "2025-09-30 16:09:17,829 - INFO - [0017] 682/1250: 0.908486542\n",
      "2025-09-30 16:09:27,099 - INFO - [0017] 744/1250: 0.566776567\n",
      "2025-09-30 16:09:37,220 - INFO - [0017] 806/1250: 0.70416809\n",
      "2025-09-30 16:09:47,431 - INFO - [0017] 868/1250: 0.466253813\n",
      "2025-09-30 16:09:55,995 - INFO - [0017] 930/1250: 0.576396707\n",
      "2025-09-30 16:10:07,159 - INFO - [0017] 992/1250: 0.471373292\n",
      "2025-09-30 16:10:17,962 - INFO - [0017] 1054/1250: 0.570394462\n",
      "2025-09-30 16:10:27,508 - INFO - [0017] 1116/1250: 1.036306256\n",
      "2025-09-30 16:10:37,284 - INFO - [0017] 1178/1250: 0.966348297\n",
      "2025-09-30 16:10:47,303 - INFO - [0017] 1240/1250: 0.824642975\n",
      "2025-09-30 16:10:57,277 - INFO - [0017]: 0.765863455 - train acc: 76.2329 - valid_acc: 75.5897\n",
      "2025-09-30 16:11:57,277 - INFO - [0018] 0/1250: 0.624326771\n",
      "2025-09-30 16:12:07,166 - INFO - [0018] 62/1250: 0.826256875\n",
      "2025-09-30 16:12:16,697 - INFO - [0018] 124/1250: 0.680340059\n",
      "2025-09-30 16:12:28,078 - INFO - [0018] 186/1250: 0.996909384\n",
      "2025-09-30 16:12:36,865 - INFO - [0018] 248/1250: 0.541220172\n",
      "2025-09-30 16:12:46,298 - INFO - [0018] 310/1250: 0.825392617\n",
      "2025-09-30 16:12:54,680 - INFO - [0018] 372/1250: 0.699181249\n",
      "2025-09-30 16:13:04,131 - INFO - [0018] 434/1250: 0.462453978\n",
      "2025-09-30 16:13:13,825 - INFO - [0018] 496/1250: 0.655261612\n",
      "2025-09-30 16:13:24,058 - INFO - [0018] 558/1250: 0.453675534\n",
      "2025-09-30 16:13:33,371 - INFO - [0018] 620/1250: 0.696024692\n",
      "2025-09-30 16:13:41,419 - INFO - [0018] 682/1250: 0.500042592\n",
      "2025-09-30 16:13:51,852 - INFO - [0018] 744/1250: 0.509918055\n",
      "2025-09-30 16:14:01,045 - INFO - [0018] 806/1250: 0.775839857\n",
      "2025-09-30 16:14:09,464 - INFO - [0018] 868/1250: 0.709627949\n",
      "2025-09-30 16:14:18,933 - INFO - [0018] 930/1250: 0.640176027\n",
      "2025-09-30 16:14:29,179 - INFO - [0018] 992/1250: 0.688798517\n",
      "2025-09-30 16:14:41,005 - INFO - [0018] 1054/1250: 1.01586775\n",
      "2025-09-30 16:14:52,288 - INFO - [0018] 1116/1250: 0.677398025\n",
      "2025-09-30 16:15:04,201 - INFO - [0018] 1178/1250: 0.475672289\n",
      "2025-09-30 16:15:14,592 - INFO - [0018] 1240/1250: 0.520875973\n",
      "2025-09-30 16:15:25,796 - INFO - [0018]: 0.788809731 - train acc: 77.676 - valid_acc: 77.0008\n",
      "2025-09-30 16:16:25,796 - INFO - [0019] 0/1250: 0.596488867\n",
      "2025-09-30 16:16:37,553 - INFO - [0019] 62/1250: 0.529147471\n",
      "2025-09-30 16:16:46,086 - INFO - [0019] 124/1250: 0.841190711\n",
      "2025-09-30 16:16:55,360 - INFO - [0019] 186/1250: 0.719009038\n",
      "2025-09-30 16:17:04,425 - INFO - [0019] 248/1250: 0.998004902\n",
      "2025-09-30 16:17:16,053 - INFO - [0019] 310/1250: 0.527878254\n",
      "2025-09-30 16:17:25,271 - INFO - [0019] 372/1250: 0.619265605\n",
      "2025-09-30 16:17:34,474 - INFO - [0019] 434/1250: 0.490883361\n",
      "2025-09-30 16:17:45,587 - INFO - [0019] 496/1250: 0.968678261\n",
      "2025-09-30 16:17:56,429 - INFO - [0019] 558/1250: 0.764017825\n",
      "2025-09-30 16:18:06,471 - INFO - [0019] 620/1250: 0.873280677\n",
      "2025-09-30 16:18:17,622 - INFO - [0019] 682/1250: 0.737810387\n",
      "2025-09-30 16:18:29,305 - INFO - [0019] 744/1250: 0.887470102\n",
      "2025-09-30 16:18:37,567 - INFO - [0019] 806/1250: 0.663225007\n",
      "2025-09-30 16:18:49,214 - INFO - [0019] 868/1250: 0.467690046\n",
      "2025-09-30 16:19:00,528 - INFO - [0019] 930/1250: 0.943484144\n",
      "2025-09-30 16:19:11,697 - INFO - [0019] 992/1250: 0.539811206\n",
      "2025-09-30 16:19:20,773 - INFO - [0019] 1054/1250: 0.893534463\n",
      "2025-09-30 16:19:31,062 - INFO - [0019] 1116/1250: 0.484853675\n",
      "2025-09-30 16:19:40,812 - INFO - [0019] 1178/1250: 1.026696185\n",
      "2025-09-30 16:19:50,372 - INFO - [0019] 1240/1250: 0.630852077\n",
      "2025-09-30 16:19:59,535 - INFO - [0019]: 0.810982957 - train acc: 79.1191 - valid_acc: 78.412\n",
      "2025-09-30 16:20:59,535 - INFO - [0020] 0/1250: 1.048790872\n",
      "2025-09-30 16:21:08,619 - INFO - [0020] 62/1250: 0.606296534\n",
      "2025-09-30 16:21:16,733 - INFO - [0020] 124/1250: 0.466194162\n",
      "2025-09-30 16:21:27,787 - INFO - [0020] 186/1250: 1.036411618\n",
      "2025-09-30 16:21:37,142 - INFO - [0020] 248/1250: 0.527954728\n",
      "2025-09-30 16:21:48,319 - INFO - [0020] 310/1250: 0.460183839\n",
      "2025-09-30 16:21:58,118 - INFO - [0020] 372/1250: 0.467021123\n",
      "2025-09-30 16:22:07,327 - INFO - [0020] 434/1250: 0.614463873\n",
      "2025-09-30 16:22:18,306 - INFO - [0020] 496/1250: 0.850089065\n",
      "2025-09-30 16:22:26,665 - INFO - [0020] 558/1250: 0.461649587\n",
      "2025-09-30 16:22:35,912 - INFO - [0020] 620/1250: 0.780162818\n",
      "2025-09-30 16:22:45,244 - INFO - [0020] 682/1250: 1.009439509\n",
      "2025-09-30 16:22:54,363 - INFO - [0020] 744/1250: 0.87477386\n",
      "2025-09-30 16:23:04,197 - INFO - [0020] 806/1250: 1.01377584\n",
      "2025-09-30 16:23:15,870 - INFO - [0020] 868/1250: 0.587502781\n",
      "2025-09-30 16:23:27,489 - INFO - [0020] 930/1250: 0.953035917\n",
      "2025-09-30 16:23:36,552 - INFO - [0020] 992/1250: 0.719362139\n",
      "2025-09-30 16:23:45,232 - INFO - [0020] 1054/1250: 0.765574182\n",
      "2025-09-30 16:23:55,400 - INFO - [0020] 1116/1250: 0.533221609\n",
      "2025-09-30 16:24:04,808 - INFO - [0020] 1178/1250: 1.042643823\n",
      "2025-09-30 16:24:15,895 - INFO - [0020] 1240/1250: 0.502232491\n",
      "2025-09-30 16:24:26,649 - INFO - [0020]: 0.831324693 - train acc: 80.5622 - valid_acc: 79.8231\n",
      "2025-09-30 16:25:26,649 - INFO - [0021] 0/1250: 0.995061658\n",
      "2025-09-30 16:25:37,315 - INFO - [0021] 62/1250: 0.736933683\n",
      "2025-09-30 16:25:48,282 - INFO - [0021] 124/1250: 0.749125069\n",
      "2025-09-30 16:25:59,229 - INFO - [0021] 186/1250: 0.883352579\n",
      "2025-09-30 16:26:07,309 - INFO - [0021] 248/1250: 0.760703364\n",
      "2025-09-30 16:26:16,278 - INFO - [0021] 310/1250: 0.528720483\n",
      "2025-09-30 16:26:25,654 - INFO - [0021] 372/1250: 0.487930079\n",
      "2025-09-30 16:26:35,468 - INFO - [0021] 434/1250: 0.766403021\n",
      "2025-09-30 16:26:46,470 - INFO - [0021] 496/1250: 0.703706942\n",
      "2025-09-30 16:26:58,124 - INFO - [0021] 558/1250: 0.85041742\n",
      "2025-09-30 16:27:08,530 - INFO - [0021] 620/1250: 0.822469479\n",
      "2025-09-30 16:27:18,220 - INFO - [0021] 682/1250: 0.969978629\n",
      "2025-09-30 16:27:28,765 - INFO - [0021] 744/1250: 0.792852751\n",
      "2025-09-30 16:27:38,094 - INFO - [0021] 806/1250: 0.641866466\n",
      "2025-09-30 16:27:49,832 - INFO - [0021] 868/1250: 0.791596605\n",
      "2025-09-30 16:27:57,918 - INFO - [0021] 930/1250: 0.540781038\n",
      "2025-09-30 16:28:06,720 - INFO - [0021] 992/1250: 0.474286671\n",
      "2025-09-30 16:28:16,172 - INFO - [0021] 1054/1250: 0.721805926\n",
      "2025-09-30 16:28:26,324 - INFO - [0021] 1116/1250: 0.981590406\n",
      "2025-09-30 16:28:38,284 - INFO - [0021] 1178/1250: 0.725409688\n",
      "2025-09-30 16:28:48,089 - INFO - [0021] 1240/1250: 1.024951407\n",
      "2025-09-30 16:28:57,691 - INFO - [0021]: 0.830758033 - train acc: 82.0054 - valid_acc: 81.2343\n",
      "2025-09-30 16:29:57,691 - INFO - [0022] 0/1250: 0.791540568\n",
      "2025-09-30 16:30:08,029 - INFO - [0022] 62/1250: 0.525079868\n",
      "2025-09-30 16:30:18,675 - INFO - [0022] 124/1250: 0.476884918\n",
      "2025-09-30 16:30:29,135 - INFO - [0022] 186/1250: 0.502741302\n",
      "2025-09-30 16:30:38,901 - INFO - [0022] 248/1250: 1.010549955\n",
      "2025-09-30 16:30:47,109 - INFO - [0022] 310/1250: 0.771379399\n",
      "2025-09-30 16:30:58,456 - INFO - [0022] 372/1250: 0.829759697\n",
      "2025-09-30 16:31:08,388 - INFO - [0022] 434/1250: 0.457896882\n",
      "2025-09-30 16:31:17,291 - INFO - [0022] 496/1250: 1.039296175\n",
      "2025-09-30 16:31:27,599 - INFO - [0022] 558/1250: 0.8791311\n",
      "2025-09-30 16:31:39,342 - INFO - [0022] 620/1250: 0.740948763\n",
      "2025-09-30 16:31:49,178 - INFO - [0022] 682/1250: 0.706737023\n",
      "2025-09-30 16:32:01,059 - INFO - [0022] 744/1250: 0.971706823\n",
      "2025-09-30 16:32:11,386 - INFO - [0022] 806/1250: 0.921174388\n",
      "2025-09-30 16:32:21,497 - INFO - [0022] 868/1250: 1.000867754\n",
      "2025-09-30 16:32:29,871 - INFO - [0022] 930/1250: 0.691663031\n",
      "2025-09-30 16:32:40,892 - INFO - [0022] 992/1250: 0.817599887\n",
      "2025-09-30 16:32:51,830 - INFO - [0022] 1054/1250: 0.759150458\n",
      "2025-09-30 16:33:01,592 - INFO - [0022] 1116/1250: 0.763467439\n",
      "2025-09-30 16:33:12,373 - INFO - [0022] 1178/1250: 0.50637409\n",
      "2025-09-30 16:33:21,285 - INFO - [0022] 1240/1250: 0.891186505\n",
      "2025-09-30 16:33:30,707 - INFO - [0022]: 0.678660626 - train acc: 83.4485 - valid_acc: 82.6454\n",
      "2025-09-30 16:34:30,707 - INFO - [0023] 0/1250: 0.544101153\n",
      "2025-09-30 16:34:38,828 - INFO - [0023] 62/1250: 0.79329381\n",
      "2025-09-30 16:34:47,442 - INFO - [0023] 124/1250: 0.539354969\n",
      "2025-09-30 16:34:56,800 - INFO - [0023] 186/1250: 1.021871969\n",
      "2025-09-30 16:35:08,673 - INFO - [0023] 248/1250: 0.462580582\n",
      "2025-09-30 16:35:18,321 - INFO - [0023] 310/1250: 0.885298721\n",
      "2025-09-30 16:35:26,621 - INFO - [0023] 372/1250: 1.014052568\n",
      "2025-09-30 16:35:35,541 - INFO - [0023] 434/1250: 1.004439863\n",
      "2025-09-30 16:35:45,640 - INFO - [0023] 496/1250: 0.837794613\n",
      "2025-09-30 16:35:54,716 - INFO - [0023] 558/1250: 0.554206574\n",
      "2025-09-30 16:36:05,505 - INFO - [0023] 620/1250: 0.703715044\n",
      "2025-09-30 16:36:14,819 - INFO - [0023] 682/1250: 1.016506232\n",
      "2025-09-30 16:36:23,801 - INFO - [0023] 744/1250: 0.525151105\n",
      "2025-09-30 16:36:34,473 - INFO - [0023] 806/1250: 0.815747242\n",
      "2025-09-30 16:36:43,179 - INFO - [0023] 868/1250: 0.522397518\n",
      "2025-09-30 16:36:51,965 - INFO - [0023] 930/1250: 0.782664995\n",
      "2025-09-30 16:37:00,562 - INFO - [0023] 992/1250: 0.903733716\n",
      "2025-09-30 16:37:11,002 - INFO - [0023] 1054/1250: 0.933604398\n",
      "2025-09-30 16:37:19,893 - INFO - [0023] 1116/1250: 0.964524854\n",
      "2025-09-30 16:37:28,079 - INFO - [0023] 1178/1250: 0.803607262\n",
      "2025-09-30 16:37:38,545 - INFO - [0023] 1240/1250: 1.03079892\n",
      "2025-09-30 16:37:50,316 - INFO - [0023]: 0.828435462 - train acc: 84.8916 - valid_acc: 84.0566\n",
      "2025-09-30 16:38:50,316 - INFO - [0024] 0/1250: 1.002526182\n",
      "2025-09-30 16:38:58,916 - INFO - [0024] 62/1250: 0.794190165\n",
      "2025-09-30 16:39:09,465 - INFO - [0024] 124/1250: 1.024227576\n",
      "2025-09-30 16:39:19,749 - INFO - [0024] 186/1250: 1.045056091\n",
      "2025-09-30 16:39:30,378 - INFO - [0024] 248/1250: 0.595341696\n",
      "2025-09-30 16:39:40,941 - INFO - [0024] 310/1250: 0.628878649\n",
      "2025-09-30 16:39:49,495 - INFO - [0024] 372/1250: 0.826782465\n",
      "2025-09-30 16:39:57,875 - INFO - [0024] 434/1250: 0.942104427\n",
      "2025-09-30 16:40:07,097 - INFO - [0024] 496/1250: 0.482181883\n",
      "2025-09-30 16:40:17,890 - INFO - [0024] 558/1250: 0.551790158\n",
      "2025-09-30 16:40:28,184 - INFO - [0024] 620/1250: 0.696495134\n",
      "2025-09-30 16:40:36,191 - INFO - [0024] 682/1250: 0.749991914\n",
      "2025-09-30 16:40:46,637 - INFO - [0024] 744/1250: 0.699941204\n",
      "2025-09-30 16:40:57,468 - INFO - [0024] 806/1250: 0.954010055\n",
      "2025-09-30 16:41:05,709 - INFO - [0024] 868/1250: 0.990120955\n",
      "2025-09-30 16:41:15,136 - INFO - [0024] 930/1250: 0.514264674\n",
      "2025-09-30 16:41:26,212 - INFO - [0024] 992/1250: 0.572274851\n",
      "2025-09-30 16:41:36,392 - INFO - [0024] 1054/1250: 0.929974149\n",
      "2025-09-30 16:41:45,137 - INFO - [0024] 1116/1250: 0.494655931\n",
      "2025-09-30 16:41:55,397 - INFO - [0024] 1178/1250: 0.488576441\n",
      "2025-09-30 16:42:06,192 - INFO - [0024] 1240/1250: 0.698482744\n",
      "2025-09-30 16:42:14,761 - INFO - [0024]: 0.67529292 - train acc: 86.3347 - valid_acc: 85.4677\n",
      "2025-09-30 16:43:14,761 - INFO - [0025] 0/1250: 0.594704583\n",
      "2025-09-30 16:43:24,183 - INFO - [0025] 62/1250: 0.734990882\n",
      "2025-09-30 16:43:33,897 - INFO - [0025] 124/1250: 0.783765498\n",
      "2025-09-30 16:43:43,301 - INFO - [0025] 186/1250: 0.621814644\n",
      "2025-09-30 16:43:52,041 - INFO - [0025] 248/1250: 0.733757837\n",
      "2025-09-30 16:44:00,949 - INFO - [0025] 310/1250: 1.044309847\n",
      "2025-09-30 16:44:09,214 - INFO - [0025] 372/1250: 0.669038865\n",
      "2025-09-30 16:44:20,940 - INFO - [0025] 434/1250: 0.675153063\n",
      "2025-09-30 16:44:29,546 - INFO - [0025] 496/1250: 0.783587792\n",
      "2025-09-30 16:44:37,784 - INFO - [0025] 558/1250: 0.653220169\n",
      "2025-09-30 16:44:47,470 - INFO - [0025] 620/1250: 0.951166495\n",
      "2025-09-30 16:44:56,996 - INFO - [0025] 682/1250: 0.825628551\n",
      "2025-09-30 16:45:05,707 - INFO - [0025] 744/1250: 0.867190096\n",
      "2025-09-30 16:45:16,343 - INFO - [0025] 806/1250: 0.812124819\n",
      "2025-09-30 16:45:26,239 - INFO - [0025] 868/1250: 1.008534684\n",
      "2025-09-30 16:45:34,969 - INFO - [0025] 930/1250: 0.860674833\n",
      "2025-09-30 16:45:45,349 - INFO - [0025] 992/1250: 1.000776905\n",
      "2025-09-30 16:45:56,873 - INFO - [0025] 1054/1250: 0.868300231\n",
      "2025-09-30 16:46:06,815 - INFO - [0025] 1116/1250: 0.79433172\n",
      "2025-09-30 16:46:18,629 - INFO - [0025] 1178/1250: 0.613020149\n",
      "2025-09-30 16:46:28,415 - INFO - [0025] 1240/1250: 0.915032922\n",
      "2025-09-30 16:46:37,141 - INFO - [0025]: 0.777370206 - train acc: 87.7778 - valid_acc: 86.8789\n",
      "2025-09-30 16:47:37,141 - INFO - Training complete! \n",
      " Saved model to trained_models/RawNet2.pth\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset\n",
    "from copy import deepcopy\n",
    "from typing import Union\n",
    "\n",
    "# ---------------------------\n",
    "# Logger\n",
    "# ---------------------------\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "def init_logger(log_file=\"experiments.log\"):\n",
    "    LOGGER.setLevel(logging.INFO)\n",
    "    fh = logging.FileHandler(log_file)\n",
    "    ch = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    fh.setFormatter(formatter)\n",
    "    ch.setFormatter(formatter)\n",
    "    if not LOGGER.handlers:\n",
    "        LOGGER.addHandler(fh)\n",
    "        LOGGER.addHandler(ch)\n",
    "\n",
    "# ---------------------------\n",
    "# RawNet config\n",
    "# ---------------------------\n",
    "RAW_NET_CONFIG = {\n",
    "    \"nb_samp\": 64600,\n",
    "    \"first_conv\": 1024,\n",
    "    \"in_channels\": 1,\n",
    "    \"filts\": [20, [20, 20], [20, 128], [128, 128]],\n",
    "    \"blocks\": [2, 4],\n",
    "    \"nb_fc_node\": 1024,\n",
    "    \"gru_node\": 1024,\n",
    "    \"nb_gru_layer\": 3,\n",
    "    \"nb_classes\": 2,\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# Test dataset loader\n",
    "# ---------------------------\n",
    "def load_dataset_test(path: Union[Path, str], pad: bool = True):\n",
    "    paths = find_wav_files(path)\n",
    "    if paths is None:\n",
    "        raise IOError(f\"No files found in {path}!\")\n",
    "    dataset = AudioDataset(paths)\n",
    "    if pad:\n",
    "        dataset = PadDataset(dataset, label=None)\n",
    "    return dataset\n",
    "\n",
    "# ---------------------------\n",
    "# Training function\n",
    "# ---------------------------\n",
    "def train_raw_net(\n",
    "        base_dir: Union[Path, str],\n",
    "        test_dir: Union[Path, str],\n",
    "        batch_size: int = 16,\n",
    "        epochs: int = 3,\n",
    "        device: str = \"cuda\",\n",
    "        model_dir: Path = None,\n",
    "        max_train_samples: int = 1000,  \n",
    "        max_val_samples: int = 500,     \n",
    "        max_test_samples: int = 1000    \n",
    "):\n",
    "    LOGGER.info(\"Loading datasets...\")\n",
    "\n",
    "    # Balanced training datasets\n",
    "    real_train = load_dataset(base_dir, pad=True, train='train', real='real', label=1, max_samples_per_class=max_train_samples)\n",
    "    fake_train = load_dataset(base_dir, pad=True, train='train', real='fake', label=0, max_samples_per_class=max_train_samples)\n",
    "    train_dataset = ConcatDataset([real_train, fake_train])\n",
    "\n",
    "    real_val = load_dataset(base_dir, pad=True, train='validation', real='real', label=1, max_samples_per_class=max_val_samples)\n",
    "    fake_val = load_dataset(base_dir, pad=True, train='validation', real='fake', label=0, max_samples_per_class=max_val_samples)\n",
    "    val_dataset = ConcatDataset([real_val, fake_val])\n",
    "\n",
    "    # Test dataset (limited for quick testing)\n",
    "    full_test_dataset = load_dataset_test(test_dir, pad=True)\n",
    "    test_dataset = Subset(full_test_dataset, list(range(min(max_test_samples, len(full_test_dataset)))))\n",
    "\n",
    "    LOGGER.info(f\"Train samples: {len(train_dataset)} | Validation samples: {len(val_dataset)} | Test samples: {len(test_dataset)}\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # Initialize model\n",
    "    # ---------------------------\n",
    "    model = RawNet(deepcopy(RAW_NET_CONFIG), device).to(device)\n",
    "    LOGGER.info(\"RawNet model initialized.\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # Initialize trainer\n",
    "    # ---------------------------\n",
    "    trainer = GDTrainer(batch_size=batch_size, device=device, epochs=epochs)\n",
    "\n",
    "    # --- MODIFIED: capture epoch-wise metrics ---\n",
    "    model, epoch_train_losses, epoch_val_accuracies = trainer.train(\n",
    "        dataset_train=train_dataset,\n",
    "        dataset_validation=val_dataset,\n",
    "        model=model,\n",
    "        model_dir=model_dir\n",
    "    )\n",
    "\n",
    "    LOGGER.info(\"Training complete!\")\n",
    "\n",
    "    return model, train_dataset, val_dataset, test_dataset, epoch_train_losses, epoch_val_accuracies\n",
    "\n",
    "# ---------------------------\n",
    "# Main\n",
    "# ---------------------------\n",
    "def main():\n",
    "    set_seed(42)\n",
    "    init_logger()\n",
    "\n",
    "    device = \"cuda\"\n",
    "    base_dir = '/kaggle/input/2024-jbnu-competition-revised'\n",
    "    test_dir = '/kaggle/input/2024-jbnu-competition-revised/test'\n",
    "\n",
    "    batch_size = 16\n",
    "    epochs = 25\n",
    "\n",
    "    # Model directory\n",
    "    model_dir = Path(\"trained_models\")\n",
    "    model_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # --- TRAIN MODEL ---\n",
    "    model, train_dataset, val_dataset, test_dataset, epoch_train_losses, epoch_val_accuracies = train_raw_net(\n",
    "        base_dir=base_dir,\n",
    "        test_dir=test_dir,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        device=device,\n",
    "        model_dir=model_dir,\n",
    "        max_train_samples=10000,   \n",
    "        max_val_samples=3000,      \n",
    "        max_test_samples=1000     \n",
    "    )\n",
    "\n",
    "    # Save variables globally if needed\n",
    "    globals().update({\n",
    "        'model': model,\n",
    "        'train_dataset': train_dataset,\n",
    "        'val_dataset': val_dataset,\n",
    "        'test_dataset': test_dataset,\n",
    "        'device': device,\n",
    "        'epoch_train_losses': epoch_train_losses,\n",
    "        'epoch_val_accuracies': epoch_val_accuracies\n",
    "    })\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_train_val_accuracy(epoch_train_accuracies, epoch_val_accuracies):\n",
    "    \"\"\"\n",
    "    Plot training and validation accuracy over epochs.\n",
    "\n",
    "    Parameters:\n",
    "    - epoch_train_accuracies: list of training accuracies per epoch\n",
    "    - epoch_val_accuracies: list of validation accuracies per epoch\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(epoch_train_accuracies) + 1)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(epochs, epoch_train_accuracies, label='Train Accuracy', marker='o')\n",
    "    plt.plot(epochs, epoch_val_accuracies, label='Validation Accuracy', marker='o', color='green')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Train & Validation Accuracy Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8660259,
     "sourceId": 80640,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
